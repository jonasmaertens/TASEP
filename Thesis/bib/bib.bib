@article{istrail_introduction_nodate,
	title = {Introduction to Markov Chains},
	author = {Istrail, Sorin},
	langid = {english},
	file = {Istrail - Introduction to Markov Chains.pdf:/Users/jonasprivat/Zotero/storage/XW9Y4MFG/Istrail - Introduction to Markov Chains.pdf:application/pdf},
}

@article{davies_introduction_nodate,
	title = {Introduction and Monte Carlo},
	author = {Davies, Robert},
	langid = {english},
	file = {Davies - Simulation - Lecture 1 - Introduction and Monte Ca.pdf:/Users/jonasprivat/Zotero/storage/YLA5LYD5/Davies - Simulation - Lecture 1 - Introduction and Monte Ca.pdf:application/pdf},
}

@online{ibm_nn,
	title = {What are Neural Networks? {\textbar} {IBM}},
	url = {https://www.ibm.com/topics/neural-networks},
	shorttitle = {What are Neural Networks?},
	abstract = {Learn about neural networks that allow programs to recognize patterns and solve common problems in artificial intelligence, machine learning and deep learning.},
	urldate = {2023-11-16},
	langid = {english},
	file = {Snapshot:/Users/jonasprivat/Zotero/storage/E9M4TP2X/neural-networks.html:text/html},
}

@book{behrends_introduction_2000,
	location = {Wiesbaden},
	title = {Introduction to Markov Chains},
	isbn = {978-3-528-06986-5 978-3-322-90157-6},
	url = {http://link.springer.com/10.1007/978-3-322-90157-6},
	series = {Advanced Lectures in Mathematics},
	publisher = {Vieweg+Teubner Verlag},
	author = {Behrends, Ehrhard},
	urldate = {2023-11-16},
	date = {2000},
	doi = {10.1007/978-3-322-90157-6},
	keywords = {calculus, Counting, Finite, Markowsche Kette, Mathematische Statistik, Wahrscheinlichkeitstheorie},
	file = {Full Text:/Users/jonasprivat/Zotero/storage/5U7DF2LH/Behrends - 2000 - Introduction to Markov Chains.pdf:application/pdf},
}


@book{sutton_reinforcement_nodate,
	title = {Reinforcement Learning: An Introduction},
	author = {Sutton, Richard S and Barto, Andrew G},
	langid = {english},
	file = {Sutton and Barto - Reinforcement Learning An Introduction.pdf:/Users/jonasprivat/Zotero/storage/6CL3U8ZH/Sutton and Barto - Reinforcement Learning An Introduction.pdf:application/pdf},
}


@online{harvard_ai,
	title = {The present and future of {AI}},
	url = {https://seas.harvard.edu/news/2021/10/present-and-future-ai},
	urldate = {2023-11-16},
	file = {The present and future of AI:/Users/jonasprivat/Zotero/storage/6RFKEZTK/present-and-future-ai.html:text/html},
}

@online{weforum_ai,
	title = {How has {AI} developed over the years and what's next?},
	url = {https://www.weforum.org/agenda/2022/12/how-ai-developed-whats-next-digital-transformation/},
	abstract = {Artificial intelligence has come a long way since the 1950s. We now have {AI} systems like {DALL}-E and {PaLM} with abilities to produce photorealistic images and interpret and generate language.},
	titleaddon = {World Economic Forum},
	urldate = {2023-11-16},
	date = {2022-12-12},
	langid = {english},
	file = {Snapshot:/Users/jonasprivat/Zotero/storage/4X5FLC3X/how-ai-developed-whats-next-digital-transformation.html:text/html},
}

@online{ibm_montecarlo,
	title = {What is Monte Carlo Simulation? {\textbar} {IBM}},
	url = {https://www.ibm.com/topics/monte-carlo-simulation},
	shorttitle = {What is Monte Carlo Simulation?},
	abstract = {Learn everything you need to know about a Monte Carlo Simulation, a type of computational algorithm that uses repeated random sampling to obtain the likelihood of a range of results of occurring.},
	urldate = {2023-11-16},
	langid = {english},
}

@book{russell_artificial_2021,
	location = {Hoboken},
	edition = {Fourth edition},
	title = {Artificial intelligence: a modern approach},
	isbn = {978-0-13-461099-3},
	series = {Pearson series in artificial intelligence},
	shorttitle = {Artificial intelligence},
	abstract = {"Updated edition of popular textbook on Artificial Intelligence. This edition specific looks at ways of keeping artificial intelligence under control"--},
	publisher = {Pearson},
	author = {Russell, Stuart J. and Norvig, Peter},
	date = {2021},
	langid = {english},
	keywords = {Artificial intelligence},
	file = {Russell and Norvig - 2021 - Artificial intelligence a modern approach.pdf:/Users/jonasprivat/Zotero/storage/ABYBGM5R/Russell and Norvig - 2021 - Artificial intelligence a modern approach.pdf:application/pdf},
}

@inreference{wiki_ai_2023,
	title = {Artificial intelligence},
	rights = {Creative Commons Attribution-{ShareAlike} License},
	url = {https://en.wikipedia.org/w/index.php?title=Artificial_intelligence&oldid=1185402635},
	abstract = {Artificial intelligence ({AI}) is the intelligence of machines or software, as opposed to the intelligence of humans or animals. It is also the field of study in computer science that develops and studies intelligent machines. "{AI}" may also refer to the machines themselves.
{AI} technology is widely used throughout industry, government and science. Some high-profile applications are: advanced web search engines (e.g., Google Search), recommendation systems (used by {YouTube}, Amazon, and Netflix), understanding human speech (such as Siri and Alexa), self-driving cars (e.g., Waymo), generative or creative tools ({ChatGPT} and {AI} art), and competing at the highest level in strategy games (such as chess and Go).Artificial intelligence was founded as an academic discipline in 1956. The field went through multiple cycles of optimism followed by disappointment and loss of funding, but after 2012, when deep learning surpassed all previous {AI} techniques, there was a vast increase in funding and interest.
The various sub-fields of {AI} research are centered around particular goals and the use of particular tools. The traditional goals of {AI} research include reasoning, knowledge representation, planning, learning, natural language processing, perception, and support for robotics. General intelligence (the ability to solve an arbitrary problem) is among the field's long-term goals.
To solve these problems, {AI} researchers have adapted and integrated a wide range of problem-solving techniques, including search and mathematical optimization, formal logic, artificial neural networks, and methods based on statistics, operations research, and economics. {AI} also draws upon psychology, linguistics, philosophy, neuroscience and many other fields.},
	booktitle = {Wikipedia},
	urldate = {2023-11-16},
	date = {2023-11-16},
	langid = {english},
	note = {Page Version {ID}: 1185402635},
	file = {Snapshot:/Users/jonasprivat/Zotero/storage/5R8VKPQ4/Artificial_intelligence.html:text/html},
}

@online{stanford-whatisai,
	title = {What is {AI}? / Basic Questions},
	url = {http://jmc.stanford.edu/artificial-intelligence/what-is-ai/index.html},
	urldate = {2023-11-16},
	file = {What is AI? / Basic Questions:/Users/jonasprivat/Zotero/storage/INAH9ER5/index.html:text/html},
}

@online{googletrends_ai,
	title = {Google Trends},
	url = {https://trends.google.com/trends/explore?date=today%205-y&q=%2Fm%2F0mkz},
	abstract = {Explore search interest for Artificial intelligence by time, location and popularity on Google Trends},
	titleaddon = {Google Trends},
	urldate = {2023-11-16},
	langid = {british},
	file = {Snapshot:/Users/jonasprivat/Zotero/storage/WGXRWQYB/explore.html:text/html},
}

@online{openai_chatgpt_intro,
	title = {Introducing {ChatGPT}},
	url = {https://openai.com/blog/chatgpt},
	abstract = {We’ve trained a model called {ChatGPT} which interacts in a conversational way. The dialogue format makes it possible for {ChatGPT} to answer followup questions, admit its mistakes, challenge incorrect premises, and reject inappropriate requests.},
	urldate = {2023-11-16},
	langid = {american},
	file = {Snapshot:/Users/jonasprivat/Zotero/storage/2PV7KLDK/chatgpt.html:text/html},
}

@online{googlengram_ai,
	title = {Google Books Ngram Viewer},
	url = {https://books.google.com/ngrams/graph?content=AI&year_start=1800&year_end=2019&corpus=en-2019&smoothing=3},
	abstract = {Google Books Ngram Viewer},
	urldate = {2023-11-16},
	langid = {english},
	file = {Snapshot:/Users/jonasprivat/Zotero/storage/M3PVUJ3T/graph.html:text/html},
}

@online{mit_nnexplained,
	title = {Explained: Neural networks},
	url = {https://news.mit.edu/2017/explained-neural-networks-deep-learning-0414},
	shorttitle = {Explained},
	abstract = {“Deep learning,” the machine-learning technique behind the best-performing artificial-intelligence systems of the past decade, is really a revival of the 70-year-old concept of neural networks.},
	titleaddon = {{MIT} News {\textbar} Massachusetts Institute of Technology},
	urldate = {2023-11-16},
	date = {2017-04-14},
	langid = {english},
	file = {Snapshot:/Users/jonasprivat/Zotero/storage/WTF7YGHG/explained-neural-networks-deep-learning-0414.html:text/html},
}

@inreference{wiki_machinelearning_2023,
	title = {Machine learning},
	rights = {Creative Commons Attribution-{ShareAlike} License},
	url = {https://en.wikipedia.org/w/index.php?title=Machine_learning&oldid=1185036623},
	abstract = {Machine learning ({ML}) is a field of study in artificial intelligence concerned with the development and study of statistical algorithms that can effectively generalize and thus perform tasks without explicit instructions. Recently, generative artificial neural networks have been able to surpass many previous approaches in performance. Machine learning approaches have been applied to large language models, computer vision, speech recognition, email filtering, agriculture and medicine, where it is too costly to develop algorithms to perform the needed tasks.The mathematical foundations of {ML} are provided by mathematical optimization (mathematical programming) methods. Data mining is a related (parallel) field of study, focusing on exploratory data analysis through unsupervised learning.{ML} is known in its application across business problems under the name predictive analytics. Although not all machine learning is statistically based, computational statistics is an important source of the field's methods.},
	booktitle = {Wikipedia},
	urldate = {2023-11-16},
	date = {2023-11-14},
	langid = {english},
	note = {Page Version {ID}: 1185036623},
	file = {Snapshot:/Users/jonasprivat/Zotero/storage/K2L2PD3W/Machine_learning.html:text/html},
}

@inreference{wiki_johnmccarthy_2023,
	title = {John {McCarthy} (computer scientist)},
	rights = {Creative Commons Attribution-{ShareAlike} License},
	url = {https://en.wikipedia.org/w/index.php?title=John_McCarthy_(computer_scientist)&oldid=1184953817},
	abstract = {John {McCarthy} (September 4, 1927 – October 24, 2011) was an American computer scientist and cognitive scientist. He was one of the founders of the discipline of artificial intelligence. He co-authored the document that coined the term "artificial intelligence" ({AI}), developed the programming language family Lisp, significantly influenced the design of the language {ALGOL}, popularized time-sharing, and invented garbage collection.
{McCarthy} spent most of his career at Stanford University. He received many accolades and honors, such as the 1971 Turing Award for his contributions to the topic of {AI}, the United States National Medal of Science, and the Kyoto Prize.},
	booktitle = {Wikipedia},
	urldate = {2023-11-16},
	date = {2023-11-13},
	langid = {english},
	note = {Page Version {ID}: 1184953817},
	file = {Snapshot:/Users/jonasprivat/Zotero/storage/MRYQE7JA/John_McCarthy_(computer_scientist).html:text/html},
}

@online{woo_fatherofai_2014,
	title = {John {McCarthy} dies at 84; the father of artificial intelligence},
	url = {https://www.latimes.com/local/obituaries/la-me-john-mccarthy-20111027-story.html},
	abstract = {The mathematician, a longtime professor at Stanford, played a seminal role in defining the field devoted to the development of intelligent machines.},
	titleaddon = {Los Angeles Times},
	author = {Woo, Elaine},
	urldate = {2023-11-16},
	date = {2014-03-20},
	langid = {american},
	note = {Section: Obituaries},
	file = {Snapshot:/Users/jonasprivat/Zotero/storage/QKXWPFTL/la-me-john-mccarthy-20111027-story.html:text/html},
}

@online{homagejohnmccarthy,
	title = {John {McCarthy}: homage to the father of Artificial Intelli...},
	url = {https://www.teneo.ai/blog/homage-to-john-mccarthy-the-father-of-artificial-intelligence-ai},
	shorttitle = {John {McCarthy}},
	abstract = {Discover the fascinating story of John {McCarthy}, the father of...},
	titleaddon = {Teneo.Ai - Transforming every phone call to a love story with your brand},
	urldate = {2023-11-16},
	langid = {english},
	file = {Snapshot:/Users/jonasprivat/Zotero/storage/KSMD868A/homage-to-john-mccarthy-the-father-of-artificial-intelligence-ai.html:text/html},
}

@article{andresen_fatherofai_2002,
	title = {John {McCarthy}: Father of {AI}},
	volume = {17},
	issn = {1541-1672},
	url = {https://www.computer.org/csdl/magazine/ex/2002/05/x5084/13rRUxE04ph},
	doi = {10.1109/MIS.2002.1039837},
	shorttitle = {John {McCarthy}},
	abstract = {null},
	pages = {84--85},
	number = {5},
	journaltitle = {{IEEE} Intelligent Systems},
	author = {Andresen, Scott L.},
	urldate = {2023-11-16},
	date = {2002-09-01},
	note = {Publisher: {IEEE} Computer Society},
}

@online{mccarthy_proposal_1955,
	title = {A {PROPOSAL} {FOR} {THE} {DARTMOUTH} {SUMMER} {RESEARCH} {PROJECT} {ON} {ARTIFICIAL} {INTELLIGENCE}},
	url = {http://www-formal.stanford.edu/jmc/history/dartmouth/dartmouth.html},
	author = {McCarthy, John and Minsky, Marvin and Rochester, Nathan and Shannon, Claude},
	urldate = {2023-11-16},
	file = {A PROPOSAL FOR THE DARTMOUTH SUMMER RESEARCH PROJECT ON ARTIFICIAL INTELLIGENCE:/Users/jonasprivat/Zotero/storage/8R5NSQD5/dartmouth.html:text/html},
}

@online{aispring,
	title = {{AI} Spring? Four Takeaways from Major Releases in Foundation Models},
	url = {https://hai.stanford.edu/news/ai-spring-four-takeaways-major-releases-foundation-models},
	shorttitle = {{AI} Spring?},
	abstract = {As companies release new, more capable models, questions around deployment and transparency arise.},
	titleaddon = {Stanford {HAI}},
	urldate = {2023-11-16},
	langid = {english},
	file = {Snapshot:/Users/jonasprivat/Zotero/storage/IAJR8ZZY/ai-spring-four-takeaways-major-releases-foundation-models.html:text/html},
}

@inproceedings{krizhevsky_imagenet_2012,
	title = {{ImageNet} Classification with Deep Convolutional Neural Networks},
	volume = {25},
	url = {https://papers.nips.cc/paper_files/paper/2012/hash/c399862d3b9d6b76c8436e924a68c45b-Abstract.html},
	abstract = {We trained a large, deep convolutional neural network to classify the 1.3 million high-resolution images in the {LSVRC}-2010 {ImageNet} training set into the 1000 different classes. On the test data, we achieved top-1 and top-5 error rates of 39.7{\textbackslash}\% and 18.9{\textbackslash}\% which is considerably better than the previous state-of-the-art results. The neural network, which has 60 million parameters and 500,000 neurons, consists of five convolutional layers, some of which are followed by max-pooling layers, and two globally connected layers with a final 1000-way softmax. To make training faster, we used non-saturating neurons and a very efficient {GPU} implementation of convolutional nets. To reduce overfitting in the globally connected layers we employed a new regularization method that proved to be very effective.},
	booktitle = {Advances in Neural Information Processing Systems},
	publisher = {Curran Associates, Inc.},
	author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
	urldate = {2023-11-16},
	date = {2012},
	file = {Full Text PDF:/Users/jonasprivat/Zotero/storage/3EWXCGHW/Krizhevsky et al. - 2012 - ImageNet Classification with Deep Convolutional Ne.pdf:application/pdf},
}

@article{hinton_deep_2012,
	title = {Deep Neural Networks for Acoustic Modeling in Speech Recognition: The Shared Views of Four Research Groups},
	volume = {29},
	issn = {1558-0792},
	url = {https://ieeexplore.ieee.org/document/6296526},
	doi = {10.1109/MSP.2012.2205597},
	shorttitle = {Deep Neural Networks for Acoustic Modeling in Speech Recognition},
	abstract = {Most current speech recognition systems use hidden Markov models ({HMMs}) to deal with the temporal variability of speech and Gaussian mixture models ({GMMs}) to determine how well each state of each {HMM} fits a frame or a short window of frames of coefficients that represents the acoustic input. An alternative way to evaluate the fit is to use a feed-forward neural network that takes several frames of coefficients as input and produces posterior probabilities over {HMM} states as output. Deep neural networks ({DNNs}) that have many hidden layers and are trained using new methods have been shown to outperform {GMMs} on a variety of speech recognition benchmarks, sometimes by a large margin. This article provides an overview of this progress and represents the shared views of four research groups that have had recent successes in using {DNNs} for acoustic modeling in speech recognition.},
	pages = {82--97},
	number = {6},
	journaltitle = {{IEEE} Signal Processing Magazine},
	author = {Hinton, Geoffrey and Deng, Li and Yu, Dong and Dahl, George E. and Mohamed, Abdel-rahman and Jaitly, Navdeep and Senior, Andrew and Vanhoucke, Vincent and Nguyen, Patrick and Sainath, Tara N. and Kingsbury, Brian},
	urldate = {2023-11-16},
	date = {2012-11},
	note = {Conference Name: {IEEE} Signal Processing Magazine},
	file = {IEEE Xplore Abstract Record:/Users/jonasprivat/Zotero/storage/RAMEF63J/6296526.html:text/html},
}

@online{google_decade_2021,
	title = {A decade in deep learning, and what's next},
	url = {https://blog.google/technology/ai/decade-deep-learning-and-whats-next/},
	abstract = {Jeff Dean and Marian Croak of Google Research take a look at progress in {AI} and how Google has applied them in helpful ways, and look ahead to a responsible and inclusive path forward.},
	titleaddon = {Google},
	urldate = {2023-11-16},
	date = {2021-11-18},
	langid = {english},
	file = {Snapshot:/Users/jonasprivat/Zotero/storage/RR8MV6XH/decade-deep-learning-and-whats-next.html:text/html},
}

@online{house_2012_2019,
	title = {2012: A Breakthrough Year for Deep Learning},
	url = {https://medium.com/neuralmagic/2012-a-breakthrough-year-for-deep-learning-2a31a6796e73},
	shorttitle = {2012},
	abstract = {Neural networks have been around for decades, with seminal early work pioneered by Geoffrey Hinton, Yann Lecun and others serving as major…},
	titleaddon = {Deep Sparse},
	author = {House, Bryan},
	urldate = {2023-11-16},
	date = {2019-07-17},
	langid = {english},
	file = {Snapshot:/Users/jonasprivat/Zotero/storage/SH25T85I/2012-a-breakthrough-year-for-deep-learning-2a31a6796e73.html:text/html},
}

@online{openai_chatgpt,
	title = {{ChatGPT}},
	url = {https://chat.openai.com},
	abstract = {A conversational {AI} system that listens, learns, and challenges},
	urldate = {2023-11-16},
	langid = {american},
	file = {Snapshot:/Users/jonasprivat/Zotero/storage/LBX4TEGW/chat.openai.com.html:text/html},
}

@online{sitnflash_history_2017,
	title = {The History of Artificial Intelligence},
	url = {https://sitn.hms.harvard.edu/flash/2017/history-artificial-intelligence/},
	abstract = {by Rockwell Anyoha Can Machines Think? In the first half of the 20th century, science fiction familiarized the world with the concept of artificially intelligent robots. It began with the “heartless” Tin man from the Wizard of Oz and continued with the humanoid robot that impersonated Maria in Metropolis. By the 1950s, we had a generation of scientists, mathematicians, and philosophers with the concept of …},
	titleaddon = {Science in the News},
	author = {{SITNFlash}},
	urldate = {2023-11-16},
	date = {2017-08-28},
	langid = {american},
	file = {Snapshot:/Users/jonasprivat/Zotero/storage/XEA3S4EZ/history-artificial-intelligence.html:text/html},
}

@online{mooreslaw,
	title = {What Is Moore's Law and Is It Still True?},
	url = {https://www.investopedia.com/terms/m/mooreslaw.asp},
	abstract = {Moore's Law refers to Gordon Moore's perception that the number of transistors on a microchip doubles every two years, while the cost of computers is halved.},
	titleaddon = {Investopedia},
	urldate = {2023-11-16},
	langid = {english},
	file = {Snapshot:/Users/jonasprivat/Zotero/storage/7B94L9NR/mooreslaw.html:text/html},
}

@article{rumelhart_learning_1986,
	title = {Learning representations by back-propagating errors},
	volume = {323},
	rights = {1986 Springer Nature Limited},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/323533a0},
	doi = {10.1038/323533a0},
	abstract = {We describe a new learning procedure, back-propagation, for networks of neurone-like units. The procedure repeatedly adjusts the weights of the connections in the network so as to minimize a measure of the difference between the actual output vector of the net and the desired output vector. As a result of the weight adjustments, internal ‘hidden’ units which are not part of the input or output come to represent important features of the task domain, and the regularities in the task are captured by the interactions of these units. The ability to create useful new features distinguishes back-propagation from earlier, simpler methods such as the perceptron-convergence procedure1.},
	pages = {533--536},
	number = {6088},
	journaltitle = {Nature},
	author = {Rumelhart, David E. and Hinton, Geoffrey E. and Williams, Ronald J.},
	urldate = {2023-11-16},
	date = {1986-10},
	langid = {english},
	note = {Number: 6088
Publisher: Nature Publishing Group},
	keywords = {Humanities and Social Sciences, multidisciplinary, Science},
}

@article{burke_recommender_2011,
	title = {Recommender Systems: An Overview},
	volume = {32},
	rights = {Copyright (c)},
	issn = {2371-9621},
	url = {https://ojs.aaai.org/aimagazine/index.php/aimagazine/article/view/2361},
	doi = {10.1609/aimag.v32i3.2361},
	shorttitle = {Recommender Systems},
	abstract = {Recommender systems are tools for interacting with large and complex information spaces. They provide a personalized view of such spaces, prioritizing items likely to be of interest to the user. The field, christened in 1995, has grown enormously in the variety of problems addressed and techniques employed, as well as in its practical applications. Recommender systems research has incorporated a wide variety of artificial intelligence techniques including machine learning, data mining, user modeling, case-based reasoning, and constraint satisfaction, among others. Personalized recommendations are an important part of many on-line e-commerce applications such as Amazon.com, Netflix, and Pandora. This wealth of practical application experience has provided inspiration to researchers to extend the reach of recommender systems into new and challenging areas. The purpose of the articles in this special issue is to take stock of the current landscape of recommender systems research and identify directions the field is now taking. This article provides an overview of the current state of the field and introduces the various articles in the special issue.},
	pages = {13--18},
	number = {3},
	journaltitle = {{AI} Magazine},
	author = {Burke, Robin and Felfernig, Alexander and Göker, Mehmet H.},
	urldate = {2023-11-16},
	date = {2011-06-05},
	langid = {english},
	note = {Number: 3},
	file = {Full Text PDF:/Users/jonasprivat/Zotero/storage/9WB8FESM/Burke et al. - 2011 - Recommender Systems An Overview.pdf:application/pdf},
}

@online{google_howweuseai,
	title = {9 ways we use {AI} in our products},
	url = {https://blog.google/technology/ai/9-ways-we-use-ai-in-our-products/},
	abstract = {Here are nine ways we use {AI} today to make our products even more helpful.},
	titleaddon = {Google},
	urldate = {2023-11-16},
	date = {2023-01-19},
	langid = {english},
	file = {Snapshot:/Users/jonasprivat/Zotero/storage/LGW4B75B/9-ways-we-use-ai-in-our-products.html:text/html},
}

@online{elevenlabs,
	title = {{ElevenLabs}: {AI} Voice Generator \& Text to Speech},
	url = {https://elevenlabs.io/},
	urldate = {2023-11-16},
	file = {ElevenLabs\: AI Voice Generator & Text to Speech:/Users/jonasprivat/Zotero/storage/7BJNLSWQ/elevenlabs.io.html:text/html},
}

@online{midjourney,
	title = {Midjourney},
	url = {https://www.midjourney.com/home?callbackUrl=%2Fexplore},
	abstract = {An independent research lab exploring new mediums of thought and expanding the imaginative powers of the human species.},
	titleaddon = {Midjourney},
	urldate = {2023-11-16},
	file = {Snapshot:/Users/jonasprivat/Zotero/storage/TBDAE88X/home.html:text/html},
}

@article{silver_mastering_2016,
	title = {Mastering the game of Go with deep neural networks and tree search},
	volume = {529},
	rights = {2016 Springer Nature Limited},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/nature16961},
	doi = {10.1038/nature16961},
	abstract = {The game of Go has long been viewed as the most challenging of classic games for artificial intelligence owing to its enormous search space and the difficulty of evaluating board positions and moves. Here we introduce a new approach to computer Go that uses ‘value networks’ to evaluate board positions and ‘policy networks’ to select moves. These deep neural networks are trained by a novel combination of supervised learning from human expert games, and reinforcement learning from games of self-play. Without any lookahead search, the neural networks play Go at the level of state-of-the-art Monte Carlo tree search programs that simulate thousands of random games of self-play. We also introduce a new search algorithm that combines Monte Carlo simulation with value and policy networks. Using this search algorithm, our program {AlphaGo} achieved a 99.8\% winning rate against other Go programs, and defeated the human European Go champion by 5 games to 0. This is the first time that a computer program has defeated a human professional player in the full-sized game of Go, a feat previously thought to be at least a decade away.},
	pages = {484--489},
	number = {7587},
	journaltitle = {Nature},
	author = {Silver, David and Huang, Aja and Maddison, Chris J. and Guez, Arthur and Sifre, Laurent and van den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and Dieleman, Sander and Grewe, Dominik and Nham, John and Kalchbrenner, Nal and Sutskever, Ilya and Lillicrap, Timothy and Leach, Madeleine and Kavukcuoglu, Koray and Graepel, Thore and Hassabis, Demis},
	urldate = {2023-11-16},
	date = {2016-01},
	langid = {english},
	note = {Number: 7587
Publisher: Nature Publishing Group},
	keywords = {Computational science, Computer science, Reward},
}

@misc{silver_mastering_2017,
	title = {Mastering Chess and Shogi by Self-Play with a General Reinforcement Learning Algorithm},
	url = {http://arxiv.org/abs/1712.01815},
	doi = {10.48550/arXiv.1712.01815},
	abstract = {The game of chess is the most widely-studied domain in the history of artificial intelligence. The strongest programs are based on a combination of sophisticated search techniques, domain-specific adaptations, and handcrafted evaluation functions that have been refined by human experts over several decades. In contrast, the {AlphaGo} Zero program recently achieved superhuman performance in the game of Go, by tabula rasa reinforcement learning from games of self-play. In this paper, we generalise this approach into a single {AlphaZero} algorithm that can achieve, tabula rasa, superhuman performance in many challenging domains. Starting from random play, and given no domain knowledge except the game rules, {AlphaZero} achieved within 24 hours a superhuman level of play in the games of chess and shogi (Japanese chess) as well as Go, and convincingly defeated a world-champion program in each case.},
	number = {{arXiv}:1712.01815},
	publisher = {{arXiv}},
	author = {Silver, David and Hubert, Thomas and Schrittwieser, Julian and Antonoglou, Ioannis and Lai, Matthew and Guez, Arthur and Lanctot, Marc and Sifre, Laurent and Kumaran, Dharshan and Graepel, Thore and Lillicrap, Timothy and Simonyan, Karen and Hassabis, Demis},
	urldate = {2023-11-16},
	date = {2017-12-05},
	eprinttype = {arxiv},
	eprint = {1712.01815 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
	file = {arXiv Fulltext PDF:/Users/jonasprivat/Zotero/storage/A2W8BFSK/Silver et al. - 2017 - Mastering Chess and Shogi by Self-Play with a Gene.pdf:application/pdf;arXiv.org Snapshot:/Users/jonasprivat/Zotero/storage/7IPJ8DST/1712.html:text/html},
}

@online{piper_ai_2019,
	title = {{AI} triumphs against the world’s top pro team in strategy game Dota 2},
	url = {https://www.vox.com/2019/4/13/18309418/open-ai-dota-triumph-og},
	abstract = {It’s the first time an {AI} has beat a world champion e-sports team.},
	titleaddon = {Vox},
	author = {Piper, Kelsey},
	urldate = {2023-11-16},
	date = {2019-04-13},
	langid = {english},
	file = {Snapshot:/Users/jonasprivat/Zotero/storage/X2DP6A2A/open-ai-dota-triumph-og.html:text/html},
}

@inreference{noauthor_artificial_2023-1,
	title = {Artificial neural network},
	rights = {Creative Commons Attribution-{ShareAlike} License},
	url = {https://en.wikipedia.org/w/index.php?title=Artificial_neural_network&oldid=1183756198},
	abstract = {Artificial neural networks ({ANNs}, also shortened to neural networks ({NNs}) or neural nets) are a branch of machine learning models that are built using principles of neuronal organization discovered by connectionism in the biological neural networks constituting animal brains.An {ANN} is based on a collection of connected units or nodes called artificial neurons, which loosely model the neurons in a biological brain. Each connection, like the synapses in a biological brain, can transmit a signal to other neurons. An artificial neuron receives signals then processes them and can signal neurons connected to it. The "signal" at a connection is a real number, and the output of each neuron is computed by some non-linear function of the sum of its inputs. The connections are called edges. Neurons and edges typically have a weight that adjusts as learning proceeds. The weight increases or decreases the strength of the signal at a connection. Neurons may have a threshold such that a signal is sent only if the aggregate signal crosses that threshold.

Typically, neurons are aggregated into layers. Different layers may perform different transformations on their inputs. Signals travel from the first layer (the input layer), to the last layer (the output layer), possibly after traversing the layers multiple times.},
	booktitle = {Wikipedia},
	urldate = {2023-11-18},
	date = {2023-11-06},
	langid = {english},
	note = {Page Version {ID}: 1183756198},
	file = {Snapshot:/Users/jonasprivat/Zotero/storage/AALQL5PG/Artificial_neural_network.html:text/html},
}

@book{aggarwal_neural_2018,
	location = {Cham},
	title = {Neural Networks and Deep Learning: A Textbook},
	isbn = {978-3-319-94462-3 978-3-319-94463-0},
	url = {http://link.springer.com/10.1007/978-3-319-94463-0},
	shorttitle = {Neural Networks and Deep Learning},
	publisher = {Springer International Publishing},
	author = {Aggarwal, Charu C.},
	urldate = {2023-11-18},
	date = {2018},
	langid = {english},
	doi = {10.1007/978-3-319-94463-0},
	keywords = {Adam, autoencoder, backpropagation, conjugate gradient-descent, Convolutional Neural Networks, Deep Learning, deep reinforcement learning, dropout, generative adversarial networks, Kohonean self-organizaing map, logistic regression, Machine Learning, Neural networks, perceptron, pretraining, Radial Basis Function Networks, Recurrent Neural Networks, Restricted Boltzmann Machines, {RMSProp}, word2vec},
	file = {Full Text PDF:/Users/jonasprivat/Zotero/storage/S82DKHBS/Aggarwal - 2018 - Neural Networks and Deep Learning A Textbook.pdf:application/pdf},
}

@online{gonfalonieri_understand_2020,
	title = {Understand Neural Networks \& Model Generalization},
	url = {https://towardsdatascience.com/understand-neural-networks-model-generalization-7baddf1c48ca},
	abstract = {The Challenge of Model Generalization, Overfitting and Regularization Methods for Deep Neural Networks},
	titleaddon = {Medium},
	author = {Gonfalonieri, Alexandre},
	urldate = {2023-11-18},
	date = {2020-01-29},
	langid = {english},
	file = {Snapshot:/Users/jonasprivat/Zotero/storage/78JNIBSX/understand-neural-networks-model-generalization-7baddf1c48ca.html:text/html},
}

@article{hornik_multilayer_1989,
	title = {Multilayer feedforward networks are universal approximators},
	volume = {2},
	issn = {0893-6080},
	url = {https://www.sciencedirect.com/science/article/pii/0893608089900208},
	doi = {10.1016/0893-6080(89)90020-8},
	abstract = {This paper rigorously establishes that standard multilayer feedforward networks with as few as one hidden layer using arbitrary squashing functions are capable of approximating any Borel measurable function from one finite dimensional space to another to any desired degree of accuracy, provided sufficiently many hidden units are available. In this sense, multilayer feedforward networks are a class of universal approximators.},
	pages = {359--366},
	number = {5},
	journaltitle = {Neural Networks},
	author = {Hornik, Kurt and Stinchcombe, Maxwell and White, Halbert},
	urldate = {2023-11-18},
	date = {1989-01-01},
	keywords = {Back-propagation networks, Feedforward networks, Mapping networks, Network representation capability, Sigma-Pi networks, Squashing functions, Stone-Weierstrass Theorem, Universal approximation},
	file = {ScienceDirect Snapshot:/Users/jonasprivat/Zotero/storage/4J6YQPBP/0893608089900208.html:text/html},
}

@book{goodfellow_deep_2016,
	location = {Cambridge, Massachusetts},
	title = {Deep Learning},
	isbn = {978-0-262-03561-3},
	abstract = {An introduction to a broad range of topics in deep learning, covering mathematical and conceptual background, deep learning techniques used in industry, and research perspectives.“Written by three experts in the field, Deep Learning is the only comprehensive book on the subject.”—Elon Musk, cochair of {OpenAI}; cofounder and {CEO} of Tesla and {SpaceXDeep} learning is a form of machine learning that enables computers to learn from experience and understand the world in terms of a hierarchy of concepts. Because the computer gathers knowledge from experience, there is no need for a human computer operator to formally specify all the knowledge that the computer needs. The hierarchy of concepts allows the computer to learn complicated concepts by building them out of simpler ones; a graph of these hierarchies would be many layers deep. This book introduces a broad range of topics in deep learning. The text offers mathematical and conceptual background, covering relevant concepts in linear algebra, probability theory and information theory, numerical computation, and machine learning. It describes deep learning techniques used by practitioners in industry, including deep feedforward networks, regularization, optimization algorithms, convolutional networks, sequence modeling, and practical methodology; and it surveys such applications as natural language processing, speech recognition, computer vision, online recommendation systems, bioinformatics, and videogames. Finally, the book offers research perspectives, covering such theoretical topics as linear factor models, autoencoders, representation learning, structured probabilistic models, Monte Carlo methods, the partition function, approximate inference, and deep generative models. Deep Learning can be used by undergraduate or graduate students planning careers in either industry or research, and by software engineers who want to begin using deep learning in their products or platforms. A website offers supplementary material for both readers and instructors.},
	pagetotal = {800},
	publisher = {The {MIT} Press},
	author = {Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron},
	date = {2016-11-18},
}

@online{raschka_is_0000,
	title = {Is the logistic sigmoid function just a rescaled version of the hyberpolic tangent (tanh) function?},
	url = {https://sebastianraschka.com/faq/docs/tanh-sigmoid-relationship.html},
	abstract = {The short answer is: yes!},
	titleaddon = {Sebastian Raschka, {PhD}},
	author = {Raschka, Sebastian},
	urldate = {2023-11-18},
	date = {0000},
	langid = {english},
	file = {Snapshot:/Users/jonasprivat/Zotero/storage/THL6DDNC/tanh-sigmoid-relationship.html:text/html},
}

@online{bettilyon_computationalgraphs_2020,
	title = {Deep Neural Networks As Computational Graphs},
	url = {https://medium.com/tebs-lab/deep-neural-networks-as-computational-graphs-867fcaa56c9},
	abstract = {{DNNs} Don’t Need To Be A Black Box},
	titleaddon = {Teb’s Lab},
	author = {Bettilyon, Tyler Elliot},
	urldate = {2023-11-23},
	date = {2020-05-05},
	langid = {english},
	file = {Snapshot:/Users/jonasprivat/Zotero/storage/3AKMBYX7/deep-neural-networks-as-computational-graphs-867fcaa56c9.html:text/html},
}

@book{haykin_neural_1998,
	location = {Upper Saddle River, {NJ}},
	edition = {Subsequent Edition},
	title = {Neural Networks: A Comprehensive Foundation: A Comprehensive Foundation: United States Edition},
	isbn = {978-0-13-273350-2},
	shorttitle = {Neural Networks},
	abstract = {For graduate-level neural network courses offered in the departments of Computer Engineering, Electrical Engineering, and Computer Science.Renowned for its thoroughness and readability, this well-organized and completely up-to-date text remains the most comprehensive treatment of neural networks from an engineering perspective. Thoroughly revised.},
	pagetotal = {842},
	publisher = {Pearson},
	author = {Haykin, Simon},
	date = {1998-07-01},
}

@misc{dubey_activation_2022,
	title = {Activation Functions in Deep Learning: A Comprehensive Survey and Benchmark},
	url = {http://arxiv.org/abs/2109.14545},
	doi = {10.48550/arXiv.2109.14545},
	shorttitle = {Activation Functions in Deep Learning},
	abstract = {Neural networks have shown tremendous growth in recent years to solve numerous problems. Various types of neural networks have been introduced to deal with different types of problems. However, the main goal of any neural network is to transform the non-linearly separable input data into more linearly separable abstract features using a hierarchy of layers. These layers are combinations of linear and nonlinear functions. The most popular and common non-linearity layers are activation functions ({AFs}), such as Logistic Sigmoid, Tanh, {ReLU}, {ELU}, Swish and Mish. In this paper, a comprehensive overview and survey is presented for {AFs} in neural networks for deep learning. Different classes of {AFs} such as Logistic Sigmoid and Tanh based, {ReLU} based, {ELU} based, and Learning based are covered. Several characteristics of {AFs} such as output range, monotonicity, and smoothness are also pointed out. A performance comparison is also performed among 18 state-of-the-art {AFs} with different networks on different types of data. The insights of {AFs} are presented to benefit the researchers for doing further research and practitioners to select among different choices. The code used for experimental comparison is released at: {\textbackslash}url\{https://github.com/shivram1987/{ActivationFunctions}\}.},
	number = {{arXiv}:2109.14545},
	publisher = {{arXiv}},
	author = {Dubey, Shiv Ram and Singh, Satish Kumar and Chaudhuri, Bidyut Baran},
	urldate = {2023-11-23},
	date = {2022-06-28},
	eprinttype = {arxiv},
	eprint = {2109.14545 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing},
	file = {arXiv Fulltext PDF:/Users/jonasprivat/Zotero/storage/BDK3PM37/Dubey et al. - 2022 - Activation Functions in Deep Learning A Comprehen.pdf:application/pdf;arXiv.org Snapshot:/Users/jonasprivat/Zotero/storage/ZKUGVVIA/2109.html:text/html},
}


@collection{rall_autodiff_1981,
	location = {Berlin, Heidelberg},
	title = {Automatic Differentiation: Techniques and Applications},
	volume = {120},
	isbn = {978-3-540-10861-0 978-3-540-38776-3},
	url = {http://link.springer.com/10.1007/3-540-10861-0},
	series = {Lecture Notes in Computer Science},
	shorttitle = {Automatic Differentiation},
	publisher = {Springer},
	editor = {Rall, Louis B.},
	editorb = {Goos, G. and Hartmanis, J. and Brauer, W. and Brinch Hansen, P. and Gries, D. and Moler, C. and Seegmüller, G. and Stoer, J. and Wirth, N.},
	editorbtype = {redactor},
	urldate = {2023-11-30},
	date = {1981},
	doi = {10.1007/3-540-10861-0},
	keywords = {addition, Applications, computation, differential equation, Differentiation, equation, integration, Jacobi, mathematical programming, Nonlinear system, Numerical integration, online, optimization, software, techniques},
	file = {Submitted Version:/Users/jonasprivat/Zotero/storage/HDZB5CHQ/Rall - 1981 - Automatic Differentiation Techniques and Applicat.pdf:application/pdf},
}

@article{adams_backprop_autodiff_nodate,
	title = {Computing Gradients with Backpropagation},
	author = {Adams, Ryan P},
	langid = {english},
	file = {Adams - Computing Gradients with Backpropagation.pdf:/Users/jonasprivat/Zotero/storage/D3I3S8IR/Adams - Computing Gradients with Backpropagation.pdf:application/pdf},
}

@book{griewank_derivatives_2008,
	title = {Evaluating Derivatives: Principles and Techniques of Algorithmic Differentiation, Second Edition},
	isbn = {978-0-89871-659-7},
	shorttitle = {Evaluating Derivatives},
	abstract = {Algorithmic, or automatic, differentiation ({AD}) is a growing area of theoretical research and software development concerned with the accurate and efficient evaluation of derivatives for function evaluations given as computer programs. The resulting derivative values are useful for all scientific computations that are based on linear, quadratic, or higher order approximations to nonlinear scalar or vector functions. This second edition covers recent developments in applications and theory, including an elegant {NP} completeness argument and an introduction to scarcity. There is also added material on checkpointing and iterative differentiation. To improve readability the more detailed analysis of memory and complexity bounds has been relegated to separate, optional chapters. The book consists of: a stand-alone introduction to the fundamentals of {AD} and its software; a thorough treatment of methods for sparse problems; and final chapters on program-reversal schedules, higher derivatives, nonsmooth problems and iterative processes.},
	pagetotal = {448},
	publisher = {{SIAM}},
	author = {Griewank, Andreas and Walther, Andrea},
	date = {2008-11-06},
	langid = {english},
	note = {Google-Books-{ID}: {qMLUIsgCwvUC}},
	keywords = {Computers / Computer Science, Computers / Computer Simulation, Computers / Programming / Algorithms, Mathematics / Linear \& Nonlinear Programming, Mathematics / Optimization, Science / Physics / Mathematical \& Computational},
}

@online{ibm_machine_learning,
	title = {What is Machine Learning? {\textbar} {IBM}},
	url = {https://www.ibm.com/topics/machine-learning},
	shorttitle = {What is Machine Learning?},
	abstract = {This introduction to machine learning provides an overview of its history, important definitions, applications and concerns within businesses today.},
	urldate = {2023-12-03},
	langid = {english},
}

@online{openai_spinning_up_rl_intro,
	title = {Part 1: Key Concepts in {RL} — Spinning Up documentation},
	url = {https://spinningup.openai.com/en/latest/spinningup/rl_intro.html},
	urldate = {2023-12-08},
	file = {Part 1\: Key Concepts in RL — Spinning Up documentation:/Users/jonasprivat/Zotero/storage/27AZ8QVV/rl_intro.html:text/html},
}


@online{openai_spinning_up_rl_part2,
	title = {Part 2: Kinds of {RL} Algorithms — Spinning Up documentation},
	url = {https://spinningup.openai.com/en/latest/spinningup/rl_intro2.html#citations-below},
	urldate = {2023-12-17},
	file = {Part 2\: Kinds of RL Algorithms — Spinning Up documentation:/Users/jonasprivat/Zotero/storage/XSF63KYR/rl_intro2.html:text/html},
}


@article{tesauro_temporal_1995,
	title = {Temporal difference learning and {TD}-Gammon},
	volume = {38},
	issn = {0001-0782},
	url = {https://dl.acm.org/doi/10.1145/203330.203343},
	doi = {10.1145/203330.203343},
	abstract = {Ever since the days of Shannon's proposal for a chess-playing algorithm [12] and Samuel's checkers-learning program [10] the domain of complex board games such as Go, chess, checkers, Othello, and backgammon has been widely regarded as an ideal testing ground for exploring a variety of concepts and approaches in artificial intelligence and machine learning. Such board games offer the challenge of tremendous complexity and sophistication required to play at expert level. At the same time, the problem inputs and performance measures are clear-cut and well defined, and the game environment is readily automated in that it is easy to simulate the board, the rules of legal play, and the rules regarding when the game is over and determining the outcome.},
	pages = {58--68},
	number = {3},
	journaltitle = {Communications of the {ACM}},
	shortjournal = {Commun. {ACM}},
	author = {Tesauro, Gerald},
	urldate = {2023-12-08},
	date = {1995},
	file = {Full Text PDF:/Users/jonasprivat/Zotero/storage/XF8XG567/Tesauro - 1995 - Temporal difference learning and TD-Gammon.pdf:application/pdf},
}

@article{kober_reinforcement_2013,
	title = {Reinforcement learning in robotics: A survey},
	volume = {32},
	issn = {0278-3649},
	url = {https://doi.org/10.1177/0278364913495721},
	doi = {10.1177/0278364913495721},
	shorttitle = {Reinforcement learning in robotics},
	abstract = {Reinforcement learning offers to robotics a framework and set of tools for the design of sophisticated and hard-to-engineer behaviors. Conversely, the challenges of robotic problems provide both inspiration, impact, and validation for developments in reinforcement learning. The relationship between disciplines has sufficient promise to be likened to that between physics and mathematics. In this article, we attempt to strengthen the links between the two research communities by providing a survey of work in reinforcement learning for behavior generation in robots. We highlight both key challenges in robot reinforcement learning as well as notable successes. We discuss how contributions tamed the complexity of the domain and study the role of algorithms, representations, and prior knowledge in achieving these successes. As a result, a particular focus of our paper lies on the choice between model-based and model-free as well as between value-function-based and policy-search methods. By analyzing a simple problem in some detail we demonstrate how reinforcement learning approaches may be profitably applied, and we note throughout open questions and the tremendous potential for future research.},
	pages = {1238--1274},
	number = {11},
	journaltitle = {The International Journal of Robotics Research},
	author = {Kober, Jens and Bagnell, J. Andrew and Peters, Jan},
	urldate = {2023-12-08},
	date = {2013-09-01},
	langid = {english},
	note = {Publisher: {SAGE} Publications Ltd {STM}},
	file = {Submitted Version:/Users/jonasprivat/Zotero/storage/H5MDZ458/Kober et al. - 2013 - Reinforcement learning in robotics A survey.pdf:application/pdf},
}

@misc{mnih_playing_2013,
	title = {Playing Atari with Deep Reinforcement Learning},
	url = {http://arxiv.org/abs/1312.5602},
	doi = {10.48550/arXiv.1312.5602},
	abstract = {We present the first deep learning model to successfully learn control policies directly from high-dimensional sensory input using reinforcement learning. The model is a convolutional neural network, trained with a variant of Q-learning, whose input is raw pixels and whose output is a value function estimating future rewards. We apply our method to seven Atari 2600 games from the Arcade Learning Environment, with no adjustment of the architecture or learning algorithm. We find that it outperforms all previous approaches on six of the games and surpasses a human expert on three of them.},
	number = {{arXiv}:1312.5602},
	publisher = {{arXiv}},
	author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Graves, Alex and Antonoglou, Ioannis and Wierstra, Daan and Riedmiller, Martin},
	urldate = {2023-12-08},
	date = {2013-12-19},
	eprinttype = {arxiv},
	eprint = {1312.5602 [cs]},
	keywords = {Computer Science - Machine Learning},
	file = {arXiv Fulltext PDF:/Users/jonasprivat/Zotero/storage/M37HCRTL/Mnih et al. - 2013 - Playing Atari with Deep Reinforcement Learning.pdf:application/pdf;arXiv.org Snapshot:/Users/jonasprivat/Zotero/storage/5M3TT28V/1312.html:text/html},
}

@misc{openai_dota_2019,
	title = {Dota 2 with Large Scale Deep Reinforcement Learning},
	url = {http://arxiv.org/abs/1912.06680},
	doi = {10.48550/arXiv.1912.06680},
	abstract = {On April 13th, 2019, {OpenAI} Five became the first {AI} system to defeat the world champions at an esports game. The game of Dota 2 presents novel challenges for {AI} systems such as long time horizons, imperfect information, and complex, continuous state-action spaces, all challenges which will become increasingly central to more capable {AI} systems. {OpenAI} Five leveraged existing reinforcement learning techniques, scaled to learn from batches of approximately 2 million frames every 2 seconds. We developed a distributed training system and tools for continual training which allowed us to train {OpenAI} Five for 10 months. By defeating the Dota 2 world champion (Team {OG}), {OpenAI} Five demonstrates that self-play reinforcement learning can achieve superhuman performance on a difficult task.},
	number = {{arXiv}:1912.06680},
	publisher = {{arXiv}},
	author = {{OpenAI} and Berner, Christopher and Brockman, Greg and Chan, Brooke and Cheung, Vicki and Dębiak, Przemysław and Dennison, Christy and Farhi, David and Fischer, Quirin and Hashme, Shariq and Hesse, Chris and Józefowicz, Rafal and Gray, Scott and Olsson, Catherine and Pachocki, Jakub and Petrov, Michael and Pinto, Henrique P. d O. and Raiman, Jonathan and Salimans, Tim and Schlatter, Jeremy and Schneider, Jonas and Sidor, Szymon and Sutskever, Ilya and Tang, Jie and Wolski, Filip and Zhang, Susan},
	urldate = {2023-12-08},
	date = {2019-12-13},
	eprinttype = {arxiv},
	eprint = {1912.06680 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:/Users/jonasprivat/Zotero/storage/43MP49R8/OpenAI et al. - 2019 - Dota 2 with Large Scale Deep Reinforcement Learnin.pdf:application/pdf;arXiv.org Snapshot:/Users/jonasprivat/Zotero/storage/WM3EH9PX/1912.html:text/html},
}

@misc{openai_learning_2019,
	title = {Learning Dexterous In-Hand Manipulation},
	url = {http://arxiv.org/abs/1808.00177},
	doi = {10.48550/arXiv.1808.00177},
	abstract = {We use reinforcement learning ({RL}) to learn dexterous in-hand manipulation policies which can perform vision-based object reorientation on a physical Shadow Dexterous Hand. The training is performed in a simulated environment in which we randomize many of the physical properties of the system like friction coefficients and an object's appearance. Our policies transfer to the physical robot despite being trained entirely in simulation. Our method does not rely on any human demonstrations, but many behaviors found in human manipulation emerge naturally, including finger gaiting, multi-finger coordination, and the controlled use of gravity. Our results were obtained using the same distributed {RL} system that was used to train {OpenAI} Five. We also include a video of our results: https://youtu.be/{jwSbzNHGflM}},
	number = {{arXiv}:1808.00177},
	publisher = {{arXiv}},
	author = {{OpenAI} and Andrychowicz, Marcin and Baker, Bowen and Chociej, Maciek and Jozefowicz, Rafal and {McGrew}, Bob and Pachocki, Jakub and Petron, Arthur and Plappert, Matthias and Powell, Glenn and Ray, Alex and Schneider, Jonas and Sidor, Szymon and Tobin, Josh and Welinder, Peter and Weng, Lilian and Zaremba, Wojciech},
	urldate = {2023-12-08},
	date = {2019-01-18},
	eprinttype = {arxiv},
	eprint = {1808.00177 [cs, stat]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Computer Science - Robotics, Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:/Users/jonasprivat/Zotero/storage/EDWQ8WMZ/OpenAI et al. - 2019 - Learning Dexterous In-Hand Manipulation.pdf:application/pdf;arXiv.org Snapshot:/Users/jonasprivat/Zotero/storage/4NZLJNM5/1808.html:text/html},
}


@incollection{serfozo_markov_2009,
	location = {Berlin, Heidelberg},
	title = {Markov Chains},
	isbn = {978-3-540-89332-5},
	url = {https://doi.org/10.1007/978-3-540-89332-5_1},
	series = {Probability and Its Applications},
	abstract = {A sequence of random variables \$\$ X\_0,X\_1,... \$\$with values in a countable set S isa Markov chain if at any time n, the future states (or values) \$\$ X\_\{n+1\}, X\_\{n+2\},... \$\$depend on the history \$\$ X\_0,...,X\_n \$\$only through the present state \$\$ X\_n \$\$.},
	pages = {1--98},
	booktitle = {Basics of Applied Stochastic Processes},
	publisher = {Springer},
	author = {Serfozo, Richard},
	editor = {Serfozo, Richard},
	urldate = {2023-12-12},
	date = {2009},
	langid = {english},
	doi = {10.1007/978-3-540-89332-5_1},
	keywords = {Invariant Measure, Markov Chain, Random Walk, Stationary Distribution, Transition Matrix},
	file = {Full Text PDF:/Users/jonasprivat/Zotero/storage/VYZ46HBL/Serfozo - 2009 - Markov Chains.pdf:application/pdf},
}

@article{watkins_learning_1989,
	title = {Learning From Delayed Rewards},
	abstract = {Photocopy. Supplied by British Library. Thesis (Ph. D.)--King's College, Cambridge, 1989.},
	author = {Watkins, Christopher},
	date = {1989-01-01},
	file = {Full Text PDF:/Users/jonasprivat/Zotero/storage/J4JHC9QL/Watkins - 1989 - Learning From Delayed Rewards.pdf:application/pdf},
}

@article{watkins_q-learning_1992,
	title = {Q-learning},
	volume = {8},
	issn = {1573-0565},
	url = {https://doi.org/10.1007/BF00992698},
	doi = {10.1007/BF00992698},
	abstract = {Q-learning (Watkins, 1989) is a simple way for agents to learn how to act optimally in controlled Markovian domains. It amounts to an incremental method for dynamic programming which imposes limited computational demands. It works by successively improving its evaluations of the quality of particular actions at particular states.},
	pages = {279--292},
	number = {3},
	journaltitle = {Machine Learning},
	shortjournal = {Mach Learn},
	author = {Watkins, Christopher J. C. H. and Dayan, Peter},
	urldate = {2023-12-17},
	date = {1992-05-01},
	langid = {english},
	keywords = {asynchronous dynamic programming, Q-learning, reinforcement learning, temporal differences},
	file = {Full Text PDF:/Users/jonasprivat/Zotero/storage/L9UV2BTG/Watkins and Dayan - 1992 - Q-learning.pdf:application/pdf},
}


@article{mnih_human-level_2015,
	title = {Human-level control through deep reinforcement learning},
	volume = {518},
	rights = {2015 Springer Nature Limited},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/nature14236},
	doi = {10.1038/nature14236},
	abstract = {An artificial agent is developed that learns to play a diverse range of classic Atari 2600 computer games directly from sensory experience, achieving a performance comparable to that of an expert human player; this work paves the way to building general-purpose learning algorithms that bridge the divide between perception and action.},
	pages = {529--533},
	number = {7540},
	journaltitle = {Nature},
	author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A. and Veness, Joel and Bellemare, Marc G. and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K. and Ostrovski, Georg and Petersen, Stig and Beattie, Charles and Sadik, Amir and Antonoglou, Ioannis and King, Helen and Kumaran, Dharshan and Wierstra, Daan and Legg, Shane and Hassabis, Demis},
	urldate = {2023-12-17},
	date = {2015-02},
	langid = {english},
	note = {Number: 7540
Publisher: Nature Publishing Group},
	keywords = {Computer science},
	file = {Full Text PDF:/Users/jonasprivat/Zotero/storage/IXWXDIEU/Mnih et al. - 2015 - Human-level control through deep reinforcement lea.pdf:application/pdf},
}



@misc{lillicrap_continuous_2015,
	title = {Continuous control with deep reinforcement learning},
	url = {http://arxiv.org/abs/1509.02971},
	doi = {10.48550/arXiv.1509.02971},
	abstract = {We adapt the ideas underlying the success of Deep Q-Learning to the continuous action domain. We present an actor-critic, model-free algorithm based on the deterministic policy gradient that can operate over continuous action spaces. Using the same learning algorithm, network architecture and hyper-parameters, our algorithm robustly solves more than 20 simulated physics tasks, including classic problems such as cartpole swing-up, dexterous manipulation, legged locomotion and car driving. Our algorithm is able to find policies whose performance is competitive with those found by a planning algorithm with full access to the dynamics of the domain and its derivatives. We further demonstrate that for many of the tasks the algorithm can learn policies end-to-end: directly from raw pixel inputs.},
	number = {{arXiv}:1509.02971},
	publisher = {{arXiv}},
	author = {Lillicrap, Timothy P. and Hunt, Jonathan J. and Pritzel, Alexander and Heess, Nicolas and Erez, Tom and Tassa, Yuval and Silver, David and Wierstra, Daan},
	urldate = {2023-12-17},
	date = {2019-07-05},
	eprinttype = {arxiv},
	eprint = {1509.02971 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:/Users/jonasprivat/Zotero/storage/Z9PFKEFW/Lillicrap et al. - 2019 - Continuous control with deep reinforcement learnin.pdf:application/pdf;arXiv.org Snapshot:/Users/jonasprivat/Zotero/storage/URPJLLP2/1509.html:text/html},
}


@misc{schaul_prioritized_2016,
	title = {Prioritized Experience Replay},
	url = {http://arxiv.org/abs/1511.05952},
	doi = {10.48550/arXiv.1511.05952},
	abstract = {Experience replay lets online reinforcement learning agents remember and reuse experiences from the past. In prior work, experience transitions were uniformly sampled from a replay memory. However, this approach simply replays transitions at the same frequency that they were originally experienced, regardless of their significance. In this paper we develop a framework for prioritizing experience, so as to replay important transitions more frequently, and therefore learn more efficiently. We use prioritized experience replay in Deep Q-Networks ({DQN}), a reinforcement learning algorithm that achieved human-level performance across many Atari games. {DQN} with prioritized experience replay achieves a new state-of-the-art, outperforming {DQN} with uniform replay on 41 out of 49 games.},
	number = {{arXiv}:1511.05952},
	publisher = {{arXiv}},
	author = {Schaul, Tom and Quan, John and Antonoglou, Ioannis and Silver, David},
	urldate = {2023-12-19},
	date = {2016-02-25},
	eprinttype = {arxiv},
	eprint = {1511.05952 [cs]},
	keywords = {Computer Science - Machine Learning},
	file = {arXiv Fulltext PDF:/Users/jonasprivat/Zotero/storage/L8YMD789/Schaul et al. - 2016 - Prioritized Experience Replay.pdf:application/pdf;arXiv.org Snapshot:/Users/jonasprivat/Zotero/storage/6YERYCNM/1511.html:text/html},
}


@article{spitzer_interaction_1970,
	title = {Interaction of Markov processes},
	volume = {5},
	issn = {0001-8708},
	url = {https://www.sciencedirect.com/science/article/pii/0001870870900344},
	doi = {10.1016/0001-8708(70)90034-4},
	pages = {246--290},
	number = {2},
	journaltitle = {Advances in Mathematics},
	shortjournal = {Advances in Mathematics},
	author = {Spitzer, Frank},
	urldate = {2023-12-19},
	date = {1970-10-01},
	file = {ScienceDirect Snapshot:/Users/jonasprivat/Zotero/storage/3QVN875L/0001870870900344.html:text/html;Spitzer - 1970 - Interaction of Markov processes.pdf:/Users/jonasprivat/Zotero/storage/T9BTAZ3E/Spitzer - 1970 - Interaction of Markov processes.pdf:application/pdf},
}

@article{goykolov_asymmetric_2007,
	title = {{ASYMMETRIC} {SIMPLE} {EXCLUSION} {PROCESS} {IN} {TWO} {DIMENSIONS}},
	author = {Goykolov, Dmytro},
	date = {2007},
	langid = {english},
	file = {Goykolov - 2007 - ASYMMETRIC SIMPLE EXCLUSION PROCESS IN TWO DIMENSI.pdf:/Users/jonasprivat/Zotero/storage/W6DHQIEB/Goykolov - 2007 - ASYMMETRIC SIMPLE EXCLUSION PROCESS IN TWO DIMENSI.pdf:application/pdf},
}

@article{blythe_nonequilibrium_2007,
	title = {Nonequilibrium Steady States of Matrix Product Form: A Solver's Guide},
	volume = {40},
	issn = {1751-8113, 1751-8121},
	url = {http://arxiv.org/abs/0706.1678},
	doi = {10.1088/1751-8113/40/46/R01},
	shorttitle = {Nonequilibrium Steady States of Matrix Product Form},
	abstract = {We consider the general problem of determining the steady state of stochastic nonequilibrium systems such as those that have been used to model (among other things) biological transport and traffic flow. We begin with a broad overview of this class of driven diffusive systems - which includes exclusion processes - focusing on interesting physical properties, such as shocks and phase transitions. We then turn our attention specifically to those models for which the exact distribution of microstates in the steady state can be expressed in a matrix product form. In addition to a gentle introduction to this matrix product approach, how it works and how it relates to similar constructions that arise in other physical contexts, we present a unified, pedagogical account of the various means by which the statistical mechanical calculations of macroscopic physical quantities are actually performed. We also review a number of more advanced topics, including nonequilibrium free energy functionals, the classification of exclusion processes involving multiple particle species, existence proofs of a matrix product state for a given model and more complicated variants of the matrix product state that allow various types of parallel dynamics to be handled. We conclude with a brief discussion of open problems for future research.},
	pages = {R333--R441},
	number = {46},
	journaltitle = {Journal of Physics A: Mathematical and Theoretical},
	shortjournal = {J. Phys. A: Math. Theor.},
	author = {Blythe, R. A. and Evans, M. R.},
	urldate = {2023-12-19},
	date = {2007-11-16},
	eprinttype = {arxiv},
	eprint = {0706.1678 [cond-mat]},
	keywords = {Condensed Matter - Statistical Mechanics},
	file = {arXiv Fulltext PDF:/Users/jonasprivat/Zotero/storage/76KEIGH7/Blythe and Evans - 2007 - Nonequilibrium Steady States of Matrix Product For.pdf:application/pdf;arXiv.org Snapshot:/Users/jonasprivat/Zotero/storage/IFFXQDZI/0706.html:text/html},
}

@article{daquila_monte_nodate,
	title = {Monte Carlo analysis of non-equilibrium steady states and relaxation kinetics in driven lattice gases},
	author = {Daquila, George Lawrence},
	langid = {english},
	file = {Daquila - Monte Carlo analysis of non-equilibrium steady sta.pdf:/Users/jonasprivat/Zotero/storage/NCRLPE2M/Daquila - Monte Carlo analysis of non-equilibrium steady sta.pdf:application/pdf},
}

@article{schutz_exact_1997,
	title = {Exact solution of the master equation for the asymmetric exclusion process},
	volume = {88},
	issn = {1572-9613},
	url = {https://doi.org/10.1007/BF02508478},
	doi = {10.1007/BF02508478},
	abstract = {Using the Bethe ansatz, we obtain the exact solution of the master equation for the totally asymmetric exclusion process on an infinite one-dimensional lattice. We derive explicit expressions for the conditional {probabilitiesP}(x1,...,{xN};t/y1,...,{yN}; 0) of {findingN} particles on lattices sitesx1,...,{xN} at timet with initial occupationy1,...,{yN} at timet=0.},
	pages = {427--445},
	number = {1},
	journaltitle = {Journal of Statistical Physics},
	shortjournal = {J Stat Phys},
	author = {Schütz, Gunter M.},
	urldate = {2023-12-22},
	date = {1997-07-01},
	langid = {english},
	keywords = {Asymmetric exclusion process, Bethe ansatz},
	file = {Full Text PDF:/Users/jonasprivat/Zotero/storage/JD4CHXRP/Schütz - 1997 - Exact solution of the master equation for the asym.pdf:application/pdf},
}

@article{macdonald_kinetics_1968,
	title = {Kinetics of biopolymerization on nucleic acid templates},
	volume = {6},
	rights = {Copyright © 1968 John Wiley \& Sons, Inc.},
	issn = {1097-0282},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/bip.1968.360060102},
	doi = {10.1002/bip.1968.360060102},
	abstract = {The kinetics of biopolymerization on nucleic acid templates is discussed. The model introduced allows for the simultaneous synthesis of several chains, of a given type, on a common template, e.g., the polyribosome situation. Each growth center [growing chain end plus enzyme(s)] moves one template site at a time, but blocks L adjacent sites. Solutions are found for the probability nj(t) that a template has a growing center that occupies the sites j — L + 1,…, j at time t. Two special sets of solutions are considered, the uniform-density solutions, for which nj(t) = n, and the more general steady-state solutions, for which dnj(t)/dt = 0. In the uniform-density case, there is an upper bound to the range of rates of polymerization that can occur. Corresponding to this maximum rate, there is one uniform solution. For a polymerization rate less than this maximum, there are two uniform solutions that give the same rate. In the steady-state case, only L = 1 is discussed. For a steady-state polymerization rate less than the maximum uniform-density rate, the steady-state solutions consist of either one or two regions of nearly uniform density, with the density value(s) assumed in the uniform region(s) being either or both of the uniform-density solutions corresponding to that polymerization rate. For a steady-state polymerization rate equal to or slightly larger than the maximum uniform-density rate, the steady-state solutions are nearly uniform to the single uniform-density solution for the maximum rate. The boundary conditions (rate of initiation and rate, of release of completed chains from the template) govern the choice among the possible solutions, i.e., determine the region(s) of uniformity and the value(s) assumed in the uniform region(s).},
	pages = {1--25},
	number = {1},
	journaltitle = {Biopolymers},
	author = {{MacDonald}, Carolyn T. and Gibbs, Julian H. and Pipkin, Allen C.},
	urldate = {2023-12-22},
	date = {1968},
	langid = {english},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/bip.1968.360060102},
	file = {Snapshot:/Users/jonasprivat/Zotero/storage/KUBQKKQN/bip.1968.html:text/html},
}


@software{maertens_smarttasep_github_2023,
	title = {jonasmaertens/{TASEP}},
	rights = {{MIT}},
	url = {https://github.com/jonasmaertens/TASEP},
	abstract = {Implements a Totally Asymmetric Simple Exclusion Process ({TASEP}) using reinforcement learning ({RL}) agents},
	author = {Märtens, Jonas},
	urldate = {2023-12-23},
	date = {2023-12-22},
	note = {original-date: 2023-10-05T16:07:08Z},
	keywords = {reinforcement-learning, simple-exclusion-process, tasep},
}


@inproceedings{lam_numba_2015,
	location = {New York, {NY}, {USA}},
	title = {Numba: a {LLVM}-based Python {JIT} compiler},
	isbn = {978-1-4503-4005-2},
	url = {https://dl.acm.org/doi/10.1145/2833157.2833162},
	doi = {10.1145/2833157.2833162},
	series = {{LLVM} '15},
	shorttitle = {Numba},
	abstract = {Dynamic, interpreted languages, like Python, are attractive for domain-experts and scientists experimenting with new ideas. However, the performance of the interpreter is often a barrier when scaling to larger data sets. This paper presents a just-in-time compiler for Python that focuses in scientific and array-oriented computing. Starting with the simple syntax of Python, Numba compiles a subset of the language into efficient machine code that is comparable in performance to a traditional compiled language. In addition, we share our experience in building a {JIT} compiler using {LLVM}[1].},
	pages = {1--6},
	booktitle = {Proceedings of the Second Workshop on the {LLVM} Compiler Infrastructure in {HPC}},
	publisher = {Association for Computing Machinery},
	author = {Lam, Siu Kwan and Pitrou, Antoine and Seibert, Stanley},
	urldate = {2023-12-24},
	date = {2015-11-15},
	keywords = {compiler, {LLVM}, Python},
	file = {Full Text PDF:/Users/jonasprivat/Zotero/storage/FJQURBAY/Lam et al. - 2015 - Numba a LLVM-based Python JIT compiler.pdf:application/pdf},
}

@misc{brockman_openai_2016,
	title = {{OpenAI} Gym},
	url = {http://arxiv.org/abs/1606.01540},
	doi = {10.48550/arXiv.1606.01540},
	abstract = {{OpenAI} Gym is a toolkit for reinforcement learning research. It includes a growing collection of benchmark problems that expose a common interface, and a website where people can share their results and compare the performance of algorithms. This whitepaper discusses the components of {OpenAI} Gym and the design decisions that went into the software.},
	number = {{arXiv}:1606.01540},
	publisher = {{arXiv}},
	author = {Brockman, Greg and Cheung, Vicki and Pettersson, Ludwig and Schneider, Jonas and Schulman, John and Tang, Jie and Zaremba, Wojciech},
	urldate = {2023-12-28},
	date = {2016-06-05},
	eprinttype = {arxiv},
	eprint = {1606.01540 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
	file = {arXiv Fulltext PDF:/Users/jonasprivat/Zotero/storage/LAP2CU8N/Brockman et al. - 2016 - OpenAI Gym.pdf:application/pdf;arXiv.org Snapshot:/Users/jonasprivat/Zotero/storage/5GR2VLJD/1606.html:text/html},
}

@misc{bou_torchrl_2023,
	title = {{TorchRL}: A data-driven decision-making library for {PyTorch}},
	url = {http://arxiv.org/abs/2306.00577},
	doi = {10.48550/arXiv.2306.00577},
	shorttitle = {{TorchRL}},
	abstract = {{PyTorch} has ascended as a premier machine learning framework, yet it lacks a native and comprehensive library for decision and control tasks suitable for large development teams dealing with complex real-world data and environments. To address this issue, we propose {TorchRL}, a generalistic control library for {PyTorch} that provides well-integrated, yet standalone components. We introduce a new and flexible {PyTorch} primitive, the {TensorDict}, which facilitates streamlined algorithm development across the many branches of Reinforcement Learning ({RL}) and control. We provide a detailed description of the building blocks and an extensive overview of the library across domains and tasks. Finally, we experimentally demonstrate its reliability and flexibility and show comparative benchmarks to demonstrate its computational efficiency. {TorchRL} fosters long-term support and is publicly available on {GitHub} for greater reproducibility and collaboration within the research community. The code is open-sourced on {GitHub}.},
	number = {{arXiv}:2306.00577},
	publisher = {{arXiv}},
	author = {Bou, Albert and Bettini, Matteo and Dittert, Sebastian and Kumar, Vikash and Sodhani, Shagun and Yang, Xiaomeng and De Fabritiis, Gianni and Moens, Vincent},
	urldate = {2024-01-01},
	date = {2023-11-27},
	eprinttype = {arxiv},
	eprint = {2306.00577 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
	file = {arXiv Fulltext PDF:/Users/jonasprivat/Zotero/storage/Y6BKRQES/Bou et al. - 2023 - TorchRL A data-driven decision-making library for.pdf:application/pdf;arXiv.org Snapshot:/Users/jonasprivat/Zotero/storage/MRIYY4C5/2306.html:text/html},
}


@misc{ruder_overview_2017,
	title = {An overview of gradient descent optimization algorithms},
	url = {http://arxiv.org/abs/1609.04747},
	doi = {10.48550/arXiv.1609.04747},
	abstract = {Gradient descent optimization algorithms, while increasingly popular, are often used as black-box optimizers, as practical explanations of their strengths and weaknesses are hard to come by. This article aims to provide the reader with intuitions with regard to the behaviour of different algorithms that will allow her to put them to use. In the course of this overview, we look at different variants of gradient descent, summarize challenges, introduce the most common optimization algorithms, review architectures in a parallel and distributed setting, and investigate additional strategies for optimizing gradient descent.},
	number = {{arXiv}:1609.04747},
	publisher = {{arXiv}},
	author = {Ruder, Sebastian},
	urldate = {2024-01-01},
	date = {2017-06-15},
	eprinttype = {arxiv},
	eprint = {1609.04747 [cs]},
	keywords = {Computer Science - Machine Learning},
	file = {arXiv Fulltext PDF:/Users/jonasprivat/Zotero/storage/FTHBND2H/Ruder - 2017 - An overview of gradient descent optimization algor.pdf:application/pdf;arXiv.org Snapshot:/Users/jonasprivat/Zotero/storage/JG2CRJEZ/1609.html:text/html},
}

@misc{kingma_adam_2017,
	title = {Adam: A Method for Stochastic Optimization},
	url = {http://arxiv.org/abs/1412.6980},
	doi = {10.48550/arXiv.1412.6980},
	shorttitle = {Adam},
	abstract = {We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss {AdaMax}, a variant of Adam based on the infinity norm.},
	number = {{arXiv}:1412.6980},
	publisher = {{arXiv}},
	author = {Kingma, Diederik P. and Ba, Jimmy},
	urldate = {2024-01-01},
	date = {2017-01-29},
	eprinttype = {arxiv},
	eprint = {1412.6980 [cs]},
	keywords = {Computer Science - Machine Learning},
	file = {arXiv Fulltext PDF:/Users/jonasprivat/Zotero/storage/DLT28QMX/Kingma and Ba - 2017 - Adam A Method for Stochastic Optimization.pdf:application/pdf;arXiv.org Snapshot:/Users/jonasprivat/Zotero/storage/3IR4SYRN/1412.html:text/html},
}

@misc{loshchilov_decoupled_2019,
	title = {Decoupled Weight Decay Regularization},
	url = {http://arxiv.org/abs/1711.05101},
	doi = {10.48550/arXiv.1711.05101},
	abstract = {L\$\_2\$ regularization and weight decay regularization are equivalent for standard stochastic gradient descent (when rescaled by the learning rate), but as we demonstrate this is {\textbackslash}emph\{not\} the case for adaptive gradient algorithms, such as Adam. While common implementations of these algorithms employ L\$\_2\$ regularization (often calling it "weight decay" in what may be misleading due to the inequivalence we expose), we propose a simple modification to recover the original formulation of weight decay regularization by {\textbackslash}emph\{decoupling\} the weight decay from the optimization steps taken w.r.t. the loss function. We provide empirical evidence that our proposed modification (i) decouples the optimal choice of weight decay factor from the setting of the learning rate for both standard {SGD} and Adam and (ii) substantially improves Adam's generalization performance, allowing it to compete with {SGD} with momentum on image classification datasets (on which it was previously typically outperformed by the latter). Our proposed decoupled weight decay has already been adopted by many researchers, and the community has implemented it in {TensorFlow} and {PyTorch}; the complete source code for our experiments is available at https://github.com/loshchil/{AdamW}-and-{SGDW}},
	number = {{arXiv}:1711.05101},
	publisher = {{arXiv}},
	author = {Loshchilov, Ilya and Hutter, Frank},
	urldate = {2024-01-01},
	date = {2019-01-04},
	eprinttype = {arxiv},
	eprint = {1711.05101 [cs, math]},
	keywords = {Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing, Mathematics - Optimization and Control},
	file = {arXiv Fulltext PDF:/Users/jonasprivat/Zotero/storage/867PAAAH/Loshchilov and Hutter - 2019 - Decoupled Weight Decay Regularization.pdf:application/pdf;arXiv.org Snapshot:/Users/jonasprivat/Zotero/storage/HBG7DESM/1711.html:text/html},
}








