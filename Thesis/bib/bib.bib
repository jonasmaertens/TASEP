@article{istrail_introduction_nodate,
	title = {Introduction to Markov Chains},
	author = {Istrail, Sorin},
	langid = {english},
	file = {Istrail - Introduction to Markov Chains.pdf:/Users/jonasprivat/Zotero/storage/XW9Y4MFG/Istrail - Introduction to Markov Chains.pdf:application/pdf},
}

@article{davies_introduction_nodate,
	title = {Introduction and Monte Carlo},
	author = {Davies, Robert},
	langid = {english},
	file = {Davies - Simulation - Lecture 1 - Introduction and Monte Ca.pdf:/Users/jonasprivat/Zotero/storage/YLA5LYD5/Davies - Simulation - Lecture 1 - Introduction and Monte Ca.pdf:application/pdf},
}

@online{ibm_nn,
	title = {What are Neural Networks? {\textbar} {IBM}},
	url = {https://www.ibm.com/topics/neural-networks},
	shorttitle = {What are Neural Networks?},
	abstract = {Learn about neural networks that allow programs to recognize patterns and solve common problems in artificial intelligence, machine learning and deep learning.},
	urldate = {2023-11-16},
	langid = {english},
	file = {Snapshot:/Users/jonasprivat/Zotero/storage/E9M4TP2X/neural-networks.html:text/html},
}

@book{behrends_introduction_2000,
	location = {Wiesbaden},
	title = {Introduction to Markov Chains},
	isbn = {978-3-528-06986-5 978-3-322-90157-6},
	url = {http://link.springer.com/10.1007/978-3-322-90157-6},
	series = {Advanced Lectures in Mathematics},
	publisher = {Vieweg+Teubner Verlag},
	author = {Behrends, Ehrhard},
	urldate = {2023-11-16},
	date = {2000},
	doi = {10.1007/978-3-322-90157-6},
	keywords = {calculus, Counting, Finite, Markowsche Kette, Mathematische Statistik, Wahrscheinlichkeitstheorie},
	file = {Full Text:/Users/jonasprivat/Zotero/storage/5U7DF2LH/Behrends - 2000 - Introduction to Markov Chains.pdf:application/pdf},
}


@book{sutton_reinforcement_nodate,
	title = {Reinforcement Learning: An Introduction},
	author = {Sutton, Richard S and Barto, Andrew G},
	langid = {english},
	file = {Sutton and Barto - Reinforcement Learning An Introduction.pdf:/Users/jonasprivat/Zotero/storage/6CL3U8ZH/Sutton and Barto - Reinforcement Learning An Introduction.pdf:application/pdf},
}


@online{harvard_ai,
	title = {The present and future of {AI}},
	url = {https://seas.harvard.edu/news/2021/10/present-and-future-ai},
	urldate = {2023-11-16},
	file = {The present and future of AI:/Users/jonasprivat/Zotero/storage/6RFKEZTK/present-and-future-ai.html:text/html},
}

@online{weforum_ai,
	title = {How has {AI} developed over the years and what's next?},
	url = {https://www.weforum.org/agenda/2022/12/how-ai-developed-whats-next-digital-transformation/},
	abstract = {Artificial intelligence has come a long way since the 1950s. We now have {AI} systems like {DALL}-E and {PaLM} with abilities to produce photorealistic images and interpret and generate language.},
	titleaddon = {World Economic Forum},
	urldate = {2023-11-16},
	date = {2022-12-12},
	langid = {english},
	file = {Snapshot:/Users/jonasprivat/Zotero/storage/4X5FLC3X/how-ai-developed-whats-next-digital-transformation.html:text/html},
}

@online{ibm_montecarlo,
	title = {What is Monte Carlo Simulation? {\textbar} {IBM}},
	url = {https://www.ibm.com/topics/monte-carlo-simulation},
	shorttitle = {What is Monte Carlo Simulation?},
	abstract = {Learn everything you need to know about a Monte Carlo Simulation, a type of computational algorithm that uses repeated random sampling to obtain the likelihood of a range of results of occurring.},
	urldate = {2023-11-16},
	langid = {english},
}

@book{russell_artificial_2021,
	location = {Hoboken},
	edition = {Fourth edition},
	title = {Artificial intelligence: a modern approach},
	isbn = {978-0-13-461099-3},
	series = {Pearson series in artificial intelligence},
	shorttitle = {Artificial intelligence},
	abstract = {"Updated edition of popular textbook on Artificial Intelligence. This edition specific looks at ways of keeping artificial intelligence under control"--},
	publisher = {Pearson},
	author = {Russell, Stuart J. and Norvig, Peter},
	date = {2021},
	langid = {english},
	keywords = {Artificial intelligence},
	file = {Russell and Norvig - 2021 - Artificial intelligence a modern approach.pdf:/Users/jonasprivat/Zotero/storage/ABYBGM5R/Russell and Norvig - 2021 - Artificial intelligence a modern approach.pdf:application/pdf},
}

@inreference{wiki_ai_2023,
	title = {Artificial intelligence},
	rights = {Creative Commons Attribution-{ShareAlike} License},
	url = {https://en.wikipedia.org/w/index.php?title=Artificial_intelligence&oldid=1185402635},
	abstract = {Artificial intelligence ({AI}) is the intelligence of machines or software, as opposed to the intelligence of humans or animals. It is also the field of study in computer science that develops and studies intelligent machines. "{AI}" may also refer to the machines themselves.
{AI} technology is widely used throughout industry, government and science. Some high-profile applications are: advanced web search engines (e.g., Google Search), recommendation systems (used by {YouTube}, Amazon, and Netflix), understanding human speech (such as Siri and Alexa), self-driving cars (e.g., Waymo), generative or creative tools ({ChatGPT} and {AI} art), and competing at the highest level in strategy games (such as chess and Go).Artificial intelligence was founded as an academic discipline in 1956. The field went through multiple cycles of optimism followed by disappointment and loss of funding, but after 2012, when deep learning surpassed all previous {AI} techniques, there was a vast increase in funding and interest.
The various sub-fields of {AI} research are centered around particular goals and the use of particular tools. The traditional goals of {AI} research include reasoning, knowledge representation, planning, learning, natural language processing, perception, and support for robotics. General intelligence (the ability to solve an arbitrary problem) is among the field's long-term goals.
To solve these problems, {AI} researchers have adapted and integrated a wide range of problem-solving techniques, including search and mathematical optimization, formal logic, artificial neural networks, and methods based on statistics, operations research, and economics. {AI} also draws upon psychology, linguistics, philosophy, neuroscience and many other fields.},
	booktitle = {Wikipedia},
	urldate = {2023-11-16},
	date = {2023-11-16},
	langid = {english},
	note = {Page Version {ID}: 1185402635},
	file = {Snapshot:/Users/jonasprivat/Zotero/storage/5R8VKPQ4/Artificial_intelligence.html:text/html},
}

@online{stanford-whatisai,
	title = {What is {AI}? / Basic Questions},
	url = {http://jmc.stanford.edu/artificial-intelligence/what-is-ai/index.html},
	urldate = {2023-11-16},
	file = {What is AI? / Basic Questions:/Users/jonasprivat/Zotero/storage/INAH9ER5/index.html:text/html},
}

@online{googletrends_ai,
	title = {Google Trends},
	url = {https://trends.google.com/trends/explore?date=today%205-y&q=%2Fm%2F0mkz},
	abstract = {Explore search interest for Artificial intelligence by time, location and popularity on Google Trends},
	titleaddon = {Google Trends},
	urldate = {2023-11-16},
	langid = {british},
	file = {Snapshot:/Users/jonasprivat/Zotero/storage/WGXRWQYB/explore.html:text/html},
}

@online{openai_chatgpt_intro,
	title = {Introducing {ChatGPT}},
	url = {https://openai.com/blog/chatgpt},
	abstract = {We’ve trained a model called {ChatGPT} which interacts in a conversational way. The dialogue format makes it possible for {ChatGPT} to answer followup questions, admit its mistakes, challenge incorrect premises, and reject inappropriate requests.},
	urldate = {2023-11-16},
	langid = {american},
	file = {Snapshot:/Users/jonasprivat/Zotero/storage/2PV7KLDK/chatgpt.html:text/html},
}

@online{googlengram_ai,
	title = {Google Books Ngram Viewer},
	url = {https://books.google.com/ngrams/graph?content=AI&year_start=1800&year_end=2019&corpus=en-2019&smoothing=3},
	abstract = {Google Books Ngram Viewer},
	urldate = {2023-11-16},
	langid = {english},
	file = {Snapshot:/Users/jonasprivat/Zotero/storage/M3PVUJ3T/graph.html:text/html},
}

@online{mit_nnexplained,
	title = {Explained: Neural networks},
	url = {https://news.mit.edu/2017/explained-neural-networks-deep-learning-0414},
	shorttitle = {Explained},
	abstract = {“Deep learning,” the machine-learning technique behind the best-performing artificial-intelligence systems of the past decade, is really a revival of the 70-year-old concept of neural networks.},
	titleaddon = {{MIT} News {\textbar} Massachusetts Institute of Technology},
	urldate = {2023-11-16},
	date = {2017-04-14},
	langid = {english},
	file = {Snapshot:/Users/jonasprivat/Zotero/storage/WTF7YGHG/explained-neural-networks-deep-learning-0414.html:text/html},
}

@inreference{wiki_machinelearning_2023,
	title = {Machine learning},
	rights = {Creative Commons Attribution-{ShareAlike} License},
	url = {https://en.wikipedia.org/w/index.php?title=Machine_learning&oldid=1185036623},
	abstract = {Machine learning ({ML}) is a field of study in artificial intelligence concerned with the development and study of statistical algorithms that can effectively generalize and thus perform tasks without explicit instructions. Recently, generative artificial neural networks have been able to surpass many previous approaches in performance. Machine learning approaches have been applied to large language models, computer vision, speech recognition, email filtering, agriculture and medicine, where it is too costly to develop algorithms to perform the needed tasks.The mathematical foundations of {ML} are provided by mathematical optimization (mathematical programming) methods. Data mining is a related (parallel) field of study, focusing on exploratory data analysis through unsupervised learning.{ML} is known in its application across business problems under the name predictive analytics. Although not all machine learning is statistically based, computational statistics is an important source of the field's methods.},
	booktitle = {Wikipedia},
	urldate = {2023-11-16},
	date = {2023-11-14},
	langid = {english},
	note = {Page Version {ID}: 1185036623},
	file = {Snapshot:/Users/jonasprivat/Zotero/storage/K2L2PD3W/Machine_learning.html:text/html},
}

@inreference{wiki_johnmccarthy_2023,
	title = {John {McCarthy} (computer scientist)},
	rights = {Creative Commons Attribution-{ShareAlike} License},
	url = {https://en.wikipedia.org/w/index.php?title=John_McCarthy_(computer_scientist)&oldid=1184953817},
	abstract = {John {McCarthy} (September 4, 1927 – October 24, 2011) was an American computer scientist and cognitive scientist. He was one of the founders of the discipline of artificial intelligence. He co-authored the document that coined the term "artificial intelligence" ({AI}), developed the programming language family Lisp, significantly influenced the design of the language {ALGOL}, popularized time-sharing, and invented garbage collection.
{McCarthy} spent most of his career at Stanford University. He received many accolades and honors, such as the 1971 Turing Award for his contributions to the topic of {AI}, the United States National Medal of Science, and the Kyoto Prize.},
	booktitle = {Wikipedia},
	urldate = {2023-11-16},
	date = {2023-11-13},
	langid = {english},
	note = {Page Version {ID}: 1184953817},
	file = {Snapshot:/Users/jonasprivat/Zotero/storage/MRYQE7JA/John_McCarthy_(computer_scientist).html:text/html},
}

@online{woo_fatherofai_2014,
	title = {John {McCarthy} dies at 84; the father of artificial intelligence},
	url = {https://www.latimes.com/local/obituaries/la-me-john-mccarthy-20111027-story.html},
	abstract = {The mathematician, a longtime professor at Stanford, played a seminal role in defining the field devoted to the development of intelligent machines.},
	titleaddon = {Los Angeles Times},
	author = {Woo, Elaine},
	urldate = {2023-11-16},
	date = {2014-03-20},
	langid = {american},
	note = {Section: Obituaries},
	file = {Snapshot:/Users/jonasprivat/Zotero/storage/QKXWPFTL/la-me-john-mccarthy-20111027-story.html:text/html},
}

@online{homagejohnmccarthy,
	title = {John {McCarthy}: homage to the father of Artificial Intelli...},
	url = {https://www.teneo.ai/blog/homage-to-john-mccarthy-the-father-of-artificial-intelligence-ai},
	shorttitle = {John {McCarthy}},
	abstract = {Discover the fascinating story of John {McCarthy}, the father of...},
	titleaddon = {Teneo.Ai - Transforming every phone call to a love story with your brand},
	urldate = {2023-11-16},
	langid = {english},
	file = {Snapshot:/Users/jonasprivat/Zotero/storage/KSMD868A/homage-to-john-mccarthy-the-father-of-artificial-intelligence-ai.html:text/html},
}

@article{andresen_fatherofai_2002,
	title = {John {McCarthy}: Father of {AI}},
	volume = {17},
	issn = {1541-1672},
	url = {https://www.computer.org/csdl/magazine/ex/2002/05/x5084/13rRUxE04ph},
	doi = {10.1109/MIS.2002.1039837},
	shorttitle = {John {McCarthy}},
	abstract = {null},
	pages = {84--85},
	number = {5},
	journaltitle = {{IEEE} Intelligent Systems},
	author = {Andresen, Scott L.},
	urldate = {2023-11-16},
	date = {2002-09-01},
	note = {Publisher: {IEEE} Computer Society},
}

@online{mccarthy_proposal_1955,
	title = {A {PROPOSAL} {FOR} {THE} {DARTMOUTH} {SUMMER} {RESEARCH} {PROJECT} {ON} {ARTIFICIAL} {INTELLIGENCE}},
	url = {http://www-formal.stanford.edu/jmc/history/dartmouth/dartmouth.html},
	author = {McCarthy, John and Minsky, Marvin and Rochester, Nathan and Shannon, Claude},
	urldate = {2023-11-16},
	file = {A PROPOSAL FOR THE DARTMOUTH SUMMER RESEARCH PROJECT ON ARTIFICIAL INTELLIGENCE:/Users/jonasprivat/Zotero/storage/8R5NSQD5/dartmouth.html:text/html},
}

@online{aispring,
	title = {{AI} Spring? Four Takeaways from Major Releases in Foundation Models},
	url = {https://hai.stanford.edu/news/ai-spring-four-takeaways-major-releases-foundation-models},
	shorttitle = {{AI} Spring?},
	abstract = {As companies release new, more capable models, questions around deployment and transparency arise.},
	titleaddon = {Stanford {HAI}},
	urldate = {2023-11-16},
	langid = {english},
	file = {Snapshot:/Users/jonasprivat/Zotero/storage/IAJR8ZZY/ai-spring-four-takeaways-major-releases-foundation-models.html:text/html},
}

@inproceedings{krizhevsky_imagenet_2012,
	title = {{ImageNet} Classification with Deep Convolutional Neural Networks},
	volume = {25},
	url = {https://papers.nips.cc/paper_files/paper/2012/hash/c399862d3b9d6b76c8436e924a68c45b-Abstract.html},
	abstract = {We trained a large, deep convolutional neural network to classify the 1.3 million high-resolution images in the {LSVRC}-2010 {ImageNet} training set into the 1000 different classes. On the test data, we achieved top-1 and top-5 error rates of 39.7{\textbackslash}\% and 18.9{\textbackslash}\% which is considerably better than the previous state-of-the-art results. The neural network, which has 60 million parameters and 500,000 neurons, consists of five convolutional layers, some of which are followed by max-pooling layers, and two globally connected layers with a final 1000-way softmax. To make training faster, we used non-saturating neurons and a very efficient {GPU} implementation of convolutional nets. To reduce overfitting in the globally connected layers we employed a new regularization method that proved to be very effective.},
	booktitle = {Advances in Neural Information Processing Systems},
	publisher = {Curran Associates, Inc.},
	author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
	urldate = {2023-11-16},
	date = {2012},
	file = {Full Text PDF:/Users/jonasprivat/Zotero/storage/3EWXCGHW/Krizhevsky et al. - 2012 - ImageNet Classification with Deep Convolutional Ne.pdf:application/pdf},
}

@article{hinton_deep_2012,
	title = {Deep Neural Networks for Acoustic Modeling in Speech Recognition: The Shared Views of Four Research Groups},
	volume = {29},
	issn = {1558-0792},
	url = {https://ieeexplore.ieee.org/document/6296526},
	doi = {10.1109/MSP.2012.2205597},
	shorttitle = {Deep Neural Networks for Acoustic Modeling in Speech Recognition},
	abstract = {Most current speech recognition systems use hidden Markov models ({HMMs}) to deal with the temporal variability of speech and Gaussian mixture models ({GMMs}) to determine how well each state of each {HMM} fits a frame or a short window of frames of coefficients that represents the acoustic input. An alternative way to evaluate the fit is to use a feed-forward neural network that takes several frames of coefficients as input and produces posterior probabilities over {HMM} states as output. Deep neural networks ({DNNs}) that have many hidden layers and are trained using new methods have been shown to outperform {GMMs} on a variety of speech recognition benchmarks, sometimes by a large margin. This article provides an overview of this progress and represents the shared views of four research groups that have had recent successes in using {DNNs} for acoustic modeling in speech recognition.},
	pages = {82--97},
	number = {6},
	journaltitle = {{IEEE} Signal Processing Magazine},
	author = {Hinton, Geoffrey and Deng, Li and Yu, Dong and Dahl, George E. and Mohamed, Abdel-rahman and Jaitly, Navdeep and Senior, Andrew and Vanhoucke, Vincent and Nguyen, Patrick and Sainath, Tara N. and Kingsbury, Brian},
	urldate = {2023-11-16},
	date = {2012-11},
	note = {Conference Name: {IEEE} Signal Processing Magazine},
	file = {IEEE Xplore Abstract Record:/Users/jonasprivat/Zotero/storage/RAMEF63J/6296526.html:text/html},
}

@online{google_decade_2021,
	title = {A decade in deep learning, and what's next},
	url = {https://blog.google/technology/ai/decade-deep-learning-and-whats-next/},
	abstract = {Jeff Dean and Marian Croak of Google Research take a look at progress in {AI} and how Google has applied them in helpful ways, and look ahead to a responsible and inclusive path forward.},
	titleaddon = {Google},
	urldate = {2023-11-16},
	date = {2021-11-18},
	langid = {english},
	file = {Snapshot:/Users/jonasprivat/Zotero/storage/RR8MV6XH/decade-deep-learning-and-whats-next.html:text/html},
}

@online{house_2012_2019,
	title = {2012: A Breakthrough Year for Deep Learning},
	url = {https://medium.com/neuralmagic/2012-a-breakthrough-year-for-deep-learning-2a31a6796e73},
	shorttitle = {2012},
	abstract = {Neural networks have been around for decades, with seminal early work pioneered by Geoffrey Hinton, Yann Lecun and others serving as major…},
	titleaddon = {Deep Sparse},
	author = {House, Bryan},
	urldate = {2023-11-16},
	date = {2019-07-17},
	langid = {english},
	file = {Snapshot:/Users/jonasprivat/Zotero/storage/SH25T85I/2012-a-breakthrough-year-for-deep-learning-2a31a6796e73.html:text/html},
}

@online{openai_chatgpt,
	title = {{ChatGPT}},
	url = {https://chat.openai.com},
	abstract = {A conversational {AI} system that listens, learns, and challenges},
	urldate = {2023-11-16},
	langid = {american},
	file = {Snapshot:/Users/jonasprivat/Zotero/storage/LBX4TEGW/chat.openai.com.html:text/html},
}

@online{sitnflash_history_2017,
	title = {The History of Artificial Intelligence},
	url = {https://sitn.hms.harvard.edu/flash/2017/history-artificial-intelligence/},
	abstract = {by Rockwell Anyoha Can Machines Think? In the first half of the 20th century, science fiction familiarized the world with the concept of artificially intelligent robots. It began with the “heartless” Tin man from the Wizard of Oz and continued with the humanoid robot that impersonated Maria in Metropolis. By the 1950s, we had a generation of scientists, mathematicians, and philosophers with the concept of …},
	titleaddon = {Science in the News},
	author = {{SITNFlash}},
	urldate = {2023-11-16},
	date = {2017-08-28},
	langid = {american},
	file = {Snapshot:/Users/jonasprivat/Zotero/storage/XEA3S4EZ/history-artificial-intelligence.html:text/html},
}

@online{mooreslaw,
	title = {What Is Moore's Law and Is It Still True?},
	url = {https://www.investopedia.com/terms/m/mooreslaw.asp},
	abstract = {Moore's Law refers to Gordon Moore's perception that the number of transistors on a microchip doubles every two years, while the cost of computers is halved.},
	titleaddon = {Investopedia},
	urldate = {2023-11-16},
	langid = {english},
	file = {Snapshot:/Users/jonasprivat/Zotero/storage/7B94L9NR/mooreslaw.html:text/html},
}

@article{rumelhart_learning_1986,
	title = {Learning representations by back-propagating errors},
	volume = {323},
	rights = {1986 Springer Nature Limited},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/323533a0},
	doi = {10.1038/323533a0},
	abstract = {We describe a new learning procedure, back-propagation, for networks of neurone-like units. The procedure repeatedly adjusts the weights of the connections in the network so as to minimize a measure of the difference between the actual output vector of the net and the desired output vector. As a result of the weight adjustments, internal ‘hidden’ units which are not part of the input or output come to represent important features of the task domain, and the regularities in the task are captured by the interactions of these units. The ability to create useful new features distinguishes back-propagation from earlier, simpler methods such as the perceptron-convergence procedure1.},
	pages = {533--536},
	number = {6088},
	journaltitle = {Nature},
	author = {Rumelhart, David E. and Hinton, Geoffrey E. and Williams, Ronald J.},
	urldate = {2023-11-16},
	date = {1986-10},
	langid = {english},
	note = {Number: 6088
Publisher: Nature Publishing Group},
	keywords = {Humanities and Social Sciences, multidisciplinary, Science},
}

@article{burke_recommender_2011,
	title = {Recommender Systems: An Overview},
	volume = {32},
	rights = {Copyright (c)},
	issn = {2371-9621},
	url = {https://ojs.aaai.org/aimagazine/index.php/aimagazine/article/view/2361},
	doi = {10.1609/aimag.v32i3.2361},
	shorttitle = {Recommender Systems},
	abstract = {Recommender systems are tools for interacting with large and complex information spaces. They provide a personalized view of such spaces, prioritizing items likely to be of interest to the user. The field, christened in 1995, has grown enormously in the variety of problems addressed and techniques employed, as well as in its practical applications. Recommender systems research has incorporated a wide variety of artificial intelligence techniques including machine learning, data mining, user modeling, case-based reasoning, and constraint satisfaction, among others. Personalized recommendations are an important part of many on-line e-commerce applications such as Amazon.com, Netflix, and Pandora. This wealth of practical application experience has provided inspiration to researchers to extend the reach of recommender systems into new and challenging areas. The purpose of the articles in this special issue is to take stock of the current landscape of recommender systems research and identify directions the field is now taking. This article provides an overview of the current state of the field and introduces the various articles in the special issue.},
	pages = {13--18},
	number = {3},
	journaltitle = {{AI} Magazine},
	author = {Burke, Robin and Felfernig, Alexander and Göker, Mehmet H.},
	urldate = {2023-11-16},
	date = {2011-06-05},
	langid = {english},
	note = {Number: 3},
	file = {Full Text PDF:/Users/jonasprivat/Zotero/storage/9WB8FESM/Burke et al. - 2011 - Recommender Systems An Overview.pdf:application/pdf},
}

@online{google_howweuseai,
	title = {9 ways we use {AI} in our products},
	url = {https://blog.google/technology/ai/9-ways-we-use-ai-in-our-products/},
	abstract = {Here are nine ways we use {AI} today to make our products even more helpful.},
	titleaddon = {Google},
	urldate = {2023-11-16},
	date = {2023-01-19},
	langid = {english},
	file = {Snapshot:/Users/jonasprivat/Zotero/storage/LGW4B75B/9-ways-we-use-ai-in-our-products.html:text/html},
}

@online{elevenlabs,
	title = {{ElevenLabs}: {AI} Voice Generator \& Text to Speech},
	url = {https://elevenlabs.io/},
	urldate = {2023-11-16},
	file = {ElevenLabs\: AI Voice Generator & Text to Speech:/Users/jonasprivat/Zotero/storage/7BJNLSWQ/elevenlabs.io.html:text/html},
}

@online{midjourney,
	title = {Midjourney},
	url = {https://www.midjourney.com/home?callbackUrl=%2Fexplore},
	abstract = {An independent research lab exploring new mediums of thought and expanding the imaginative powers of the human species.},
	titleaddon = {Midjourney},
	urldate = {2023-11-16},
	file = {Snapshot:/Users/jonasprivat/Zotero/storage/TBDAE88X/home.html:text/html},
}

@article{silver_mastering_2016,
	title = {Mastering the game of Go with deep neural networks and tree search},
	volume = {529},
	rights = {2016 Springer Nature Limited},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/nature16961},
	doi = {10.1038/nature16961},
	abstract = {The game of Go has long been viewed as the most challenging of classic games for artificial intelligence owing to its enormous search space and the difficulty of evaluating board positions and moves. Here we introduce a new approach to computer Go that uses ‘value networks’ to evaluate board positions and ‘policy networks’ to select moves. These deep neural networks are trained by a novel combination of supervised learning from human expert games, and reinforcement learning from games of self-play. Without any lookahead search, the neural networks play Go at the level of state-of-the-art Monte Carlo tree search programs that simulate thousands of random games of self-play. We also introduce a new search algorithm that combines Monte Carlo simulation with value and policy networks. Using this search algorithm, our program {AlphaGo} achieved a 99.8\% winning rate against other Go programs, and defeated the human European Go champion by 5 games to 0. This is the first time that a computer program has defeated a human professional player in the full-sized game of Go, a feat previously thought to be at least a decade away.},
	pages = {484--489},
	number = {7587},
	journaltitle = {Nature},
	author = {Silver, David and Huang, Aja and Maddison, Chris J. and Guez, Arthur and Sifre, Laurent and van den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and Dieleman, Sander and Grewe, Dominik and Nham, John and Kalchbrenner, Nal and Sutskever, Ilya and Lillicrap, Timothy and Leach, Madeleine and Kavukcuoglu, Koray and Graepel, Thore and Hassabis, Demis},
	urldate = {2023-11-16},
	date = {2016-01},
	langid = {english},
	note = {Number: 7587
Publisher: Nature Publishing Group},
	keywords = {Computational science, Computer science, Reward},
}

@misc{silver_mastering_2017,
	title = {Mastering Chess and Shogi by Self-Play with a General Reinforcement Learning Algorithm},
	url = {http://arxiv.org/abs/1712.01815},
	doi = {10.48550/arXiv.1712.01815},
	abstract = {The game of chess is the most widely-studied domain in the history of artificial intelligence. The strongest programs are based on a combination of sophisticated search techniques, domain-specific adaptations, and handcrafted evaluation functions that have been refined by human experts over several decades. In contrast, the {AlphaGo} Zero program recently achieved superhuman performance in the game of Go, by tabula rasa reinforcement learning from games of self-play. In this paper, we generalise this approach into a single {AlphaZero} algorithm that can achieve, tabula rasa, superhuman performance in many challenging domains. Starting from random play, and given no domain knowledge except the game rules, {AlphaZero} achieved within 24 hours a superhuman level of play in the games of chess and shogi (Japanese chess) as well as Go, and convincingly defeated a world-champion program in each case.},
	number = {{arXiv}:1712.01815},
	publisher = {{arXiv}},
	author = {Silver, David and Hubert, Thomas and Schrittwieser, Julian and Antonoglou, Ioannis and Lai, Matthew and Guez, Arthur and Lanctot, Marc and Sifre, Laurent and Kumaran, Dharshan and Graepel, Thore and Lillicrap, Timothy and Simonyan, Karen and Hassabis, Demis},
	urldate = {2023-11-16},
	date = {2017-12-05},
	eprinttype = {arxiv},
	eprint = {1712.01815 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
	file = {arXiv Fulltext PDF:/Users/jonasprivat/Zotero/storage/A2W8BFSK/Silver et al. - 2017 - Mastering Chess and Shogi by Self-Play with a Gene.pdf:application/pdf;arXiv.org Snapshot:/Users/jonasprivat/Zotero/storage/7IPJ8DST/1712.html:text/html},
}

@online{piper_ai_2019,
	title = {{AI} triumphs against the world’s top pro team in strategy game Dota 2},
	url = {https://www.vox.com/2019/4/13/18309418/open-ai-dota-triumph-og},
	abstract = {It’s the first time an {AI} has beat a world champion e-sports team.},
	titleaddon = {Vox},
	author = {Piper, Kelsey},
	urldate = {2023-11-16},
	date = {2019-04-13},
	langid = {english},
	file = {Snapshot:/Users/jonasprivat/Zotero/storage/X2DP6A2A/open-ai-dota-triumph-og.html:text/html},
}

@inreference{noauthor_artificial_2023-1,
	title = {Artificial neural network},
	rights = {Creative Commons Attribution-{ShareAlike} License},
	url = {https://en.wikipedia.org/w/index.php?title=Artificial_neural_network&oldid=1183756198},
	abstract = {Artificial neural networks ({ANNs}, also shortened to neural networks ({NNs}) or neural nets) are a branch of machine learning models that are built using principles of neuronal organization discovered by connectionism in the biological neural networks constituting animal brains.An {ANN} is based on a collection of connected units or nodes called artificial neurons, which loosely model the neurons in a biological brain. Each connection, like the synapses in a biological brain, can transmit a signal to other neurons. An artificial neuron receives signals then processes them and can signal neurons connected to it. The "signal" at a connection is a real number, and the output of each neuron is computed by some non-linear function of the sum of its inputs. The connections are called edges. Neurons and edges typically have a weight that adjusts as learning proceeds. The weight increases or decreases the strength of the signal at a connection. Neurons may have a threshold such that a signal is sent only if the aggregate signal crosses that threshold.

Typically, neurons are aggregated into layers. Different layers may perform different transformations on their inputs. Signals travel from the first layer (the input layer), to the last layer (the output layer), possibly after traversing the layers multiple times.},
	booktitle = {Wikipedia},
	urldate = {2023-11-18},
	date = {2023-11-06},
	langid = {english},
	note = {Page Version {ID}: 1183756198},
	file = {Snapshot:/Users/jonasprivat/Zotero/storage/AALQL5PG/Artificial_neural_network.html:text/html},
}

@book{aggarwal_neural_2018,
	location = {Cham},
	title = {Neural Networks and Deep Learning: A Textbook},
	isbn = {978-3-319-94462-3 978-3-319-94463-0},
	url = {http://link.springer.com/10.1007/978-3-319-94463-0},
	shorttitle = {Neural Networks and Deep Learning},
	publisher = {Springer International Publishing},
	author = {Aggarwal, Charu C.},
	urldate = {2023-11-18},
	date = {2018},
	langid = {english},
	doi = {10.1007/978-3-319-94463-0},
	keywords = {Adam, autoencoder, backpropagation, conjugate gradient-descent, Convolutional Neural Networks, Deep Learning, deep reinforcement learning, dropout, generative adversarial networks, Kohonean self-organizaing map, logistic regression, Machine Learning, Neural networks, perceptron, pretraining, Radial Basis Function Networks, Recurrent Neural Networks, Restricted Boltzmann Machines, {RMSProp}, word2vec},
	file = {Full Text PDF:/Users/jonasprivat/Zotero/storage/S82DKHBS/Aggarwal - 2018 - Neural Networks and Deep Learning A Textbook.pdf:application/pdf},
}

@online{gonfalonieri_understand_2020,
	title = {Understand Neural Networks \& Model Generalization},
	url = {https://towardsdatascience.com/understand-neural-networks-model-generalization-7baddf1c48ca},
	abstract = {The Challenge of Model Generalization, Overfitting and Regularization Methods for Deep Neural Networks},
	titleaddon = {Medium},
	author = {Gonfalonieri, Alexandre},
	urldate = {2023-11-18},
	date = {2020-01-29},
	langid = {english},
	file = {Snapshot:/Users/jonasprivat/Zotero/storage/78JNIBSX/understand-neural-networks-model-generalization-7baddf1c48ca.html:text/html},
}

@article{hornik_multilayer_1989,
	title = {Multilayer feedforward networks are universal approximators},
	volume = {2},
	issn = {0893-6080},
	url = {https://www.sciencedirect.com/science/article/pii/0893608089900208},
	doi = {10.1016/0893-6080(89)90020-8},
	abstract = {This paper rigorously establishes that standard multilayer feedforward networks with as few as one hidden layer using arbitrary squashing functions are capable of approximating any Borel measurable function from one finite dimensional space to another to any desired degree of accuracy, provided sufficiently many hidden units are available. In this sense, multilayer feedforward networks are a class of universal approximators.},
	pages = {359--366},
	number = {5},
	journaltitle = {Neural Networks},
	author = {Hornik, Kurt and Stinchcombe, Maxwell and White, Halbert},
	urldate = {2023-11-18},
	date = {1989-01-01},
	keywords = {Back-propagation networks, Feedforward networks, Mapping networks, Network representation capability, Sigma-Pi networks, Squashing functions, Stone-Weierstrass Theorem, Universal approximation},
	file = {ScienceDirect Snapshot:/Users/jonasprivat/Zotero/storage/4J6YQPBP/0893608089900208.html:text/html},
}

@book{goodfellow_deep_2016,
	location = {Cambridge, Massachusetts},
	title = {Deep Learning},
	isbn = {978-0-262-03561-3},
	abstract = {An introduction to a broad range of topics in deep learning, covering mathematical and conceptual background, deep learning techniques used in industry, and research perspectives.“Written by three experts in the field, Deep Learning is the only comprehensive book on the subject.”—Elon Musk, cochair of {OpenAI}; cofounder and {CEO} of Tesla and {SpaceXDeep} learning is a form of machine learning that enables computers to learn from experience and understand the world in terms of a hierarchy of concepts. Because the computer gathers knowledge from experience, there is no need for a human computer operator to formally specify all the knowledge that the computer needs. The hierarchy of concepts allows the computer to learn complicated concepts by building them out of simpler ones; a graph of these hierarchies would be many layers deep. This book introduces a broad range of topics in deep learning. The text offers mathematical and conceptual background, covering relevant concepts in linear algebra, probability theory and information theory, numerical computation, and machine learning. It describes deep learning techniques used by practitioners in industry, including deep feedforward networks, regularization, optimization algorithms, convolutional networks, sequence modeling, and practical methodology; and it surveys such applications as natural language processing, speech recognition, computer vision, online recommendation systems, bioinformatics, and videogames. Finally, the book offers research perspectives, covering such theoretical topics as linear factor models, autoencoders, representation learning, structured probabilistic models, Monte Carlo methods, the partition function, approximate inference, and deep generative models. Deep Learning can be used by undergraduate or graduate students planning careers in either industry or research, and by software engineers who want to begin using deep learning in their products or platforms. A website offers supplementary material for both readers and instructors.},
	pagetotal = {800},
	publisher = {The {MIT} Press},
	author = {Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron},
	date = {2016-11-18},
}

@online{raschka_is_0000,
	title = {Is the logistic sigmoid function just a rescaled version of the hyberpolic tangent (tanh) function?},
	url = {https://sebastianraschka.com/faq/docs/tanh-sigmoid-relationship.html},
	abstract = {The short answer is: yes!},
	titleaddon = {Sebastian Raschka, {PhD}},
	author = {Raschka, Sebastian},
	urldate = {2023-11-18},
	date = {0000},
	langid = {english},
	file = {Snapshot:/Users/jonasprivat/Zotero/storage/THL6DDNC/tanh-sigmoid-relationship.html:text/html},
}

@online{bettilyon_computationalgraphs_2020,
	title = {Deep Neural Networks As Computational Graphs},
	url = {https://medium.com/tebs-lab/deep-neural-networks-as-computational-graphs-867fcaa56c9},
	abstract = {{DNNs} Don’t Need To Be A Black Box},
	titleaddon = {Teb’s Lab},
	author = {Bettilyon, Tyler Elliot},
	urldate = {2023-11-23},
	date = {2020-05-05},
	langid = {english},
	file = {Snapshot:/Users/jonasprivat/Zotero/storage/3AKMBYX7/deep-neural-networks-as-computational-graphs-867fcaa56c9.html:text/html},
}

@book{haykin_neural_1998,
	location = {Upper Saddle River, {NJ}},
	edition = {Subsequent Edition},
	title = {Neural Networks: A Comprehensive Foundation: A Comprehensive Foundation: United States Edition},
	isbn = {978-0-13-273350-2},
	shorttitle = {Neural Networks},
	abstract = {For graduate-level neural network courses offered in the departments of Computer Engineering, Electrical Engineering, and Computer Science.Renowned for its thoroughness and readability, this well-organized and completely up-to-date text remains the most comprehensive treatment of neural networks from an engineering perspective. Thoroughly revised.},
	pagetotal = {842},
	publisher = {Pearson},
	author = {Haykin, Simon},
	date = {1998-07-01},
}

@misc{dubey_activation_2022,
	title = {Activation Functions in Deep Learning: A Comprehensive Survey and Benchmark},
	url = {http://arxiv.org/abs/2109.14545},
	doi = {10.48550/arXiv.2109.14545},
	shorttitle = {Activation Functions in Deep Learning},
	abstract = {Neural networks have shown tremendous growth in recent years to solve numerous problems. Various types of neural networks have been introduced to deal with different types of problems. However, the main goal of any neural network is to transform the non-linearly separable input data into more linearly separable abstract features using a hierarchy of layers. These layers are combinations of linear and nonlinear functions. The most popular and common non-linearity layers are activation functions ({AFs}), such as Logistic Sigmoid, Tanh, {ReLU}, {ELU}, Swish and Mish. In this paper, a comprehensive overview and survey is presented for {AFs} in neural networks for deep learning. Different classes of {AFs} such as Logistic Sigmoid and Tanh based, {ReLU} based, {ELU} based, and Learning based are covered. Several characteristics of {AFs} such as output range, monotonicity, and smoothness are also pointed out. A performance comparison is also performed among 18 state-of-the-art {AFs} with different networks on different types of data. The insights of {AFs} are presented to benefit the researchers for doing further research and practitioners to select among different choices. The code used for experimental comparison is released at: {\textbackslash}url\{https://github.com/shivram1987/{ActivationFunctions}\}.},
	number = {{arXiv}:2109.14545},
	publisher = {{arXiv}},
	author = {Dubey, Shiv Ram and Singh, Satish Kumar and Chaudhuri, Bidyut Baran},
	urldate = {2023-11-23},
	date = {2022-06-28},
	eprinttype = {arxiv},
	eprint = {2109.14545 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing},
	file = {arXiv Fulltext PDF:/Users/jonasprivat/Zotero/storage/BDK3PM37/Dubey et al. - 2022 - Activation Functions in Deep Learning A Comprehen.pdf:application/pdf;arXiv.org Snapshot:/Users/jonasprivat/Zotero/storage/ZKUGVVIA/2109.html:text/html},
}


@collection{rall_autodiff_1981,
	location = {Berlin, Heidelberg},
	title = {Automatic Differentiation: Techniques and Applications},
	volume = {120},
	isbn = {978-3-540-10861-0 978-3-540-38776-3},
	url = {http://link.springer.com/10.1007/3-540-10861-0},
	series = {Lecture Notes in Computer Science},
	shorttitle = {Automatic Differentiation},
	publisher = {Springer},
	editor = {Rall, Louis B.},
	editorb = {Goos, G. and Hartmanis, J. and Brauer, W. and Brinch Hansen, P. and Gries, D. and Moler, C. and Seegmüller, G. and Stoer, J. and Wirth, N.},
	editorbtype = {redactor},
	urldate = {2023-11-30},
	date = {1981},
	doi = {10.1007/3-540-10861-0},
	keywords = {addition, Applications, computation, differential equation, Differentiation, equation, integration, Jacobi, mathematical programming, Nonlinear system, Numerical integration, online, optimization, software, techniques},
	file = {Submitted Version:/Users/jonasprivat/Zotero/storage/HDZB5CHQ/Rall - 1981 - Automatic Differentiation Techniques and Applicat.pdf:application/pdf},
}

@article{adams_backprop_autodiff_nodate,
	title = {Computing Gradients with Backpropagation},
	author = {Adams, Ryan P},
	langid = {english},
	file = {Adams - Computing Gradients with Backpropagation.pdf:/Users/jonasprivat/Zotero/storage/D3I3S8IR/Adams - Computing Gradients with Backpropagation.pdf:application/pdf},
}

@book{griewank_derivatives_2008,
	title = {Evaluating Derivatives: Principles and Techniques of Algorithmic Differentiation, Second Edition},
	isbn = {978-0-89871-659-7},
	shorttitle = {Evaluating Derivatives},
	abstract = {Algorithmic, or automatic, differentiation ({AD}) is a growing area of theoretical research and software development concerned with the accurate and efficient evaluation of derivatives for function evaluations given as computer programs. The resulting derivative values are useful for all scientific computations that are based on linear, quadratic, or higher order approximations to nonlinear scalar or vector functions. This second edition covers recent developments in applications and theory, including an elegant {NP} completeness argument and an introduction to scarcity. There is also added material on checkpointing and iterative differentiation. To improve readability the more detailed analysis of memory and complexity bounds has been relegated to separate, optional chapters. The book consists of: a stand-alone introduction to the fundamentals of {AD} and its software; a thorough treatment of methods for sparse problems; and final chapters on program-reversal schedules, higher derivatives, nonsmooth problems and iterative processes.},
	pagetotal = {448},
	publisher = {{SIAM}},
	author = {Griewank, Andreas and Walther, Andrea},
	date = {2008-11-06},
	langid = {english},
	note = {Google-Books-{ID}: {qMLUIsgCwvUC}},
	keywords = {Computers / Computer Science, Computers / Computer Simulation, Computers / Programming / Algorithms, Mathematics / Linear \& Nonlinear Programming, Mathematics / Optimization, Science / Physics / Mathematical \& Computational},
}

@online{ibm_machine_learning,
	title = {What is Machine Learning? {\textbar} {IBM}},
	url = {https://www.ibm.com/topics/machine-learning},
	shorttitle = {What is Machine Learning?},
	abstract = {This introduction to machine learning provides an overview of its history, important definitions, applications and concerns within businesses today.},
	urldate = {2023-12-03},
	langid = {english},
}

@online{openai_spinning_up_rl_intro,
	title = {Part 1: Key Concepts in {RL} — Spinning Up documentation},
	url = {https://spinningup.openai.com/en/latest/spinningup/rl_intro.html},
	urldate = {2023-12-08},
	file = {Part 1\: Key Concepts in RL — Spinning Up documentation:/Users/jonasprivat/Zotero/storage/27AZ8QVV/rl_intro.html:text/html},
}


@online{openai_spinning_up_rl_part2,
	title = {Part 2: Kinds of {RL} Algorithms — Spinning Up documentation},
	url = {https://spinningup.openai.com/en/latest/spinningup/rl_intro2.html#citations-below},
	urldate = {2023-12-17},
	file = {Part 2\: Kinds of RL Algorithms — Spinning Up documentation:/Users/jonasprivat/Zotero/storage/XSF63KYR/rl_intro2.html:text/html},
}


@article{tesauro_temporal_1995,
	title = {Temporal difference learning and {TD}-Gammon},
	volume = {38},
	issn = {0001-0782},
	url = {https://dl.acm.org/doi/10.1145/203330.203343},
	doi = {10.1145/203330.203343},
	abstract = {Ever since the days of Shannon's proposal for a chess-playing algorithm [12] and Samuel's checkers-learning program [10] the domain of complex board games such as Go, chess, checkers, Othello, and backgammon has been widely regarded as an ideal testing ground for exploring a variety of concepts and approaches in artificial intelligence and machine learning. Such board games offer the challenge of tremendous complexity and sophistication required to play at expert level. At the same time, the problem inputs and performance measures are clear-cut and well defined, and the game environment is readily automated in that it is easy to simulate the board, the rules of legal play, and the rules regarding when the game is over and determining the outcome.},
	pages = {58--68},
	number = {3},
	journaltitle = {Communications of the {ACM}},
	shortjournal = {Commun. {ACM}},
	author = {Tesauro, Gerald},
	urldate = {2023-12-08},
	date = {1995},
	file = {Full Text PDF:/Users/jonasprivat/Zotero/storage/XF8XG567/Tesauro - 1995 - Temporal difference learning and TD-Gammon.pdf:application/pdf},
}

@article{kober_reinforcement_2013,
	title = {Reinforcement learning in robotics: A survey},
	volume = {32},
	issn = {0278-3649},
	url = {https://doi.org/10.1177/0278364913495721},
	doi = {10.1177/0278364913495721},
	shorttitle = {Reinforcement learning in robotics},
	abstract = {Reinforcement learning offers to robotics a framework and set of tools for the design of sophisticated and hard-to-engineer behaviors. Conversely, the challenges of robotic problems provide both inspiration, impact, and validation for developments in reinforcement learning. The relationship between disciplines has sufficient promise to be likened to that between physics and mathematics. In this article, we attempt to strengthen the links between the two research communities by providing a survey of work in reinforcement learning for behavior generation in robots. We highlight both key challenges in robot reinforcement learning as well as notable successes. We discuss how contributions tamed the complexity of the domain and study the role of algorithms, representations, and prior knowledge in achieving these successes. As a result, a particular focus of our paper lies on the choice between model-based and model-free as well as between value-function-based and policy-search methods. By analyzing a simple problem in some detail we demonstrate how reinforcement learning approaches may be profitably applied, and we note throughout open questions and the tremendous potential for future research.},
	pages = {1238--1274},
	number = {11},
	journaltitle = {The International Journal of Robotics Research},
	author = {Kober, Jens and Bagnell, J. Andrew and Peters, Jan},
	urldate = {2023-12-08},
	date = {2013-09-01},
	langid = {english},
	note = {Publisher: {SAGE} Publications Ltd {STM}},
	file = {Submitted Version:/Users/jonasprivat/Zotero/storage/H5MDZ458/Kober et al. - 2013 - Reinforcement learning in robotics A survey.pdf:application/pdf},
}

@misc{mnih_playing_2013,
	title = {Playing Atari with Deep Reinforcement Learning},
	url = {http://arxiv.org/abs/1312.5602},
	doi = {10.48550/arXiv.1312.5602},
	abstract = {We present the first deep learning model to successfully learn control policies directly from high-dimensional sensory input using reinforcement learning. The model is a convolutional neural network, trained with a variant of Q-learning, whose input is raw pixels and whose output is a value function estimating future rewards. We apply our method to seven Atari 2600 games from the Arcade Learning Environment, with no adjustment of the architecture or learning algorithm. We find that it outperforms all previous approaches on six of the games and surpasses a human expert on three of them.},
	number = {{arXiv}:1312.5602},
	publisher = {{arXiv}},
	author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Graves, Alex and Antonoglou, Ioannis and Wierstra, Daan and Riedmiller, Martin},
	urldate = {2023-12-08},
	date = {2013-12-19},
	eprinttype = {arxiv},
	eprint = {1312.5602 [cs]},
	keywords = {Computer Science - Machine Learning},
	file = {arXiv Fulltext PDF:/Users/jonasprivat/Zotero/storage/M37HCRTL/Mnih et al. - 2013 - Playing Atari with Deep Reinforcement Learning.pdf:application/pdf;arXiv.org Snapshot:/Users/jonasprivat/Zotero/storage/5M3TT28V/1312.html:text/html},
}

@misc{openai_dota_2019,
	title = {Dota 2 with Large Scale Deep Reinforcement Learning},
	url = {http://arxiv.org/abs/1912.06680},
	doi = {10.48550/arXiv.1912.06680},
	abstract = {On April 13th, 2019, {OpenAI} Five became the first {AI} system to defeat the world champions at an esports game. The game of Dota 2 presents novel challenges for {AI} systems such as long time horizons, imperfect information, and complex, continuous state-action spaces, all challenges which will become increasingly central to more capable {AI} systems. {OpenAI} Five leveraged existing reinforcement learning techniques, scaled to learn from batches of approximately 2 million frames every 2 seconds. We developed a distributed training system and tools for continual training which allowed us to train {OpenAI} Five for 10 months. By defeating the Dota 2 world champion (Team {OG}), {OpenAI} Five demonstrates that self-play reinforcement learning can achieve superhuman performance on a difficult task.},
	number = {{arXiv}:1912.06680},
	publisher = {{arXiv}},
	author = {{OpenAI} and Berner, Christopher and Brockman, Greg and Chan, Brooke and Cheung, Vicki and Dębiak, Przemysław and Dennison, Christy and Farhi, David and Fischer, Quirin and Hashme, Shariq and Hesse, Chris and Józefowicz, Rafal and Gray, Scott and Olsson, Catherine and Pachocki, Jakub and Petrov, Michael and Pinto, Henrique P. d O. and Raiman, Jonathan and Salimans, Tim and Schlatter, Jeremy and Schneider, Jonas and Sidor, Szymon and Sutskever, Ilya and Tang, Jie and Wolski, Filip and Zhang, Susan},
	urldate = {2023-12-08},
	date = {2019-12-13},
	eprinttype = {arxiv},
	eprint = {1912.06680 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:/Users/jonasprivat/Zotero/storage/43MP49R8/OpenAI et al. - 2019 - Dota 2 with Large Scale Deep Reinforcement Learnin.pdf:application/pdf;arXiv.org Snapshot:/Users/jonasprivat/Zotero/storage/WM3EH9PX/1912.html:text/html},
}

@misc{openai_learning_2019,
	title = {Learning Dexterous In-Hand Manipulation},
	url = {http://arxiv.org/abs/1808.00177},
	doi = {10.48550/arXiv.1808.00177},
	abstract = {We use reinforcement learning ({RL}) to learn dexterous in-hand manipulation policies which can perform vision-based object reorientation on a physical Shadow Dexterous Hand. The training is performed in a simulated environment in which we randomize many of the physical properties of the system like friction coefficients and an object's appearance. Our policies transfer to the physical robot despite being trained entirely in simulation. Our method does not rely on any human demonstrations, but many behaviors found in human manipulation emerge naturally, including finger gaiting, multi-finger coordination, and the controlled use of gravity. Our results were obtained using the same distributed {RL} system that was used to train {OpenAI} Five. We also include a video of our results: https://youtu.be/{jwSbzNHGflM}},
	number = {{arXiv}:1808.00177},
	publisher = {{arXiv}},
	author = {{OpenAI} and Andrychowicz, Marcin and Baker, Bowen and Chociej, Maciek and Jozefowicz, Rafal and {McGrew}, Bob and Pachocki, Jakub and Petron, Arthur and Plappert, Matthias and Powell, Glenn and Ray, Alex and Schneider, Jonas and Sidor, Szymon and Tobin, Josh and Welinder, Peter and Weng, Lilian and Zaremba, Wojciech},
	urldate = {2023-12-08},
	date = {2019-01-18},
	eprinttype = {arxiv},
	eprint = {1808.00177 [cs, stat]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Computer Science - Robotics, Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:/Users/jonasprivat/Zotero/storage/EDWQ8WMZ/OpenAI et al. - 2019 - Learning Dexterous In-Hand Manipulation.pdf:application/pdf;arXiv.org Snapshot:/Users/jonasprivat/Zotero/storage/4NZLJNM5/1808.html:text/html},
}


@incollection{serfozo_markov_2009,
	location = {Berlin, Heidelberg},
	title = {Markov Chains},
	isbn = {978-3-540-89332-5},
	url = {https://doi.org/10.1007/978-3-540-89332-5_1},
	series = {Probability and Its Applications},
	abstract = {A sequence of random variables \$\$ X\_0,X\_1,... \$\$with values in a countable set S isa Markov chain if at any time n, the future states (or values) \$\$ X\_\{n+1\}, X\_\{n+2\},... \$\$depend on the history \$\$ X\_0,...,X\_n \$\$only through the present state \$\$ X\_n \$\$.},
	pages = {1--98},
	booktitle = {Basics of Applied Stochastic Processes},
	publisher = {Springer},
	author = {Serfozo, Richard},
	editor = {Serfozo, Richard},
	urldate = {2023-12-12},
	date = {2009},
	langid = {english},
	doi = {10.1007/978-3-540-89332-5_1},
	keywords = {Invariant Measure, Markov Chain, Random Walk, Stationary Distribution, Transition Matrix},
	file = {Full Text PDF:/Users/jonasprivat/Zotero/storage/VYZ46HBL/Serfozo - 2009 - Markov Chains.pdf:application/pdf},
}

@article{watkins_learning_1989,
	title = {Learning From Delayed Rewards},
	abstract = {Photocopy. Supplied by British Library. Thesis (Ph. D.)--King's College, Cambridge, 1989.},
	author = {Watkins, Christopher},
	date = {1989-01-01},
	file = {Full Text PDF:/Users/jonasprivat/Zotero/storage/J4JHC9QL/Watkins - 1989 - Learning From Delayed Rewards.pdf:application/pdf},
}

@article{watkins_q-learning_1992,
	title = {Q-learning},
	volume = {8},
	issn = {1573-0565},
	url = {https://doi.org/10.1007/BF00992698},
	doi = {10.1007/BF00992698},
	abstract = {Q-learning (Watkins, 1989) is a simple way for agents to learn how to act optimally in controlled Markovian domains. It amounts to an incremental method for dynamic programming which imposes limited computational demands. It works by successively improving its evaluations of the quality of particular actions at particular states.},
	pages = {279--292},
	number = {3},
	journaltitle = {Machine Learning},
	shortjournal = {Mach Learn},
	author = {Watkins, Christopher J. C. H. and Dayan, Peter},
	urldate = {2023-12-17},
	date = {1992-05-01},
	langid = {english},
	keywords = {asynchronous dynamic programming, Q-learning, reinforcement learning, temporal differences},
	file = {Full Text PDF:/Users/jonasprivat/Zotero/storage/L9UV2BTG/Watkins and Dayan - 1992 - Q-learning.pdf:application/pdf},
}


@article{mnih_human-level_2015,
	title = {Human-level control through deep reinforcement learning},
	volume = {518},
	rights = {2015 Springer Nature Limited},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/nature14236},
	doi = {10.1038/nature14236},
	abstract = {An artificial agent is developed that learns to play a diverse range of classic Atari 2600 computer games directly from sensory experience, achieving a performance comparable to that of an expert human player; this work paves the way to building general-purpose learning algorithms that bridge the divide between perception and action.},
	pages = {529--533},
	number = {7540},
	journaltitle = {Nature},
	author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A. and Veness, Joel and Bellemare, Marc G. and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K. and Ostrovski, Georg and Petersen, Stig and Beattie, Charles and Sadik, Amir and Antonoglou, Ioannis and King, Helen and Kumaran, Dharshan and Wierstra, Daan and Legg, Shane and Hassabis, Demis},
	urldate = {2023-12-17},
	date = {2015-02},
	langid = {english},
	note = {Number: 7540
Publisher: Nature Publishing Group},
	keywords = {Computer science},
	file = {Full Text PDF:/Users/jonasprivat/Zotero/storage/IXWXDIEU/Mnih et al. - 2015 - Human-level control through deep reinforcement lea.pdf:application/pdf},
}



@misc{lillicrap_continuous_2015,
	title = {Continuous control with deep reinforcement learning},
	url = {http://arxiv.org/abs/1509.02971},
	doi = {10.48550/arXiv.1509.02971},
	abstract = {We adapt the ideas underlying the success of Deep Q-Learning to the continuous action domain. We present an actor-critic, model-free algorithm based on the deterministic policy gradient that can operate over continuous action spaces. Using the same learning algorithm, network architecture and hyper-parameters, our algorithm robustly solves more than 20 simulated physics tasks, including classic problems such as cartpole swing-up, dexterous manipulation, legged locomotion and car driving. Our algorithm is able to find policies whose performance is competitive with those found by a planning algorithm with full access to the dynamics of the domain and its derivatives. We further demonstrate that for many of the tasks the algorithm can learn policies end-to-end: directly from raw pixel inputs.},
	number = {{arXiv}:1509.02971},
	publisher = {{arXiv}},
	author = {Lillicrap, Timothy P. and Hunt, Jonathan J. and Pritzel, Alexander and Heess, Nicolas and Erez, Tom and Tassa, Yuval and Silver, David and Wierstra, Daan},
	urldate = {2023-12-17},
	date = {2019-07-05},
	eprinttype = {arxiv},
	eprint = {1509.02971 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:/Users/jonasprivat/Zotero/storage/Z9PFKEFW/Lillicrap et al. - 2019 - Continuous control with deep reinforcement learnin.pdf:application/pdf;arXiv.org Snapshot:/Users/jonasprivat/Zotero/storage/URPJLLP2/1509.html:text/html},
}


@misc{schaul_prioritized_2016,
	title = {Prioritized Experience Replay},
	url = {http://arxiv.org/abs/1511.05952},
	doi = {10.48550/arXiv.1511.05952},
	abstract = {Experience replay lets online reinforcement learning agents remember and reuse experiences from the past. In prior work, experience transitions were uniformly sampled from a replay memory. However, this approach simply replays transitions at the same frequency that they were originally experienced, regardless of their significance. In this paper we develop a framework for prioritizing experience, so as to replay important transitions more frequently, and therefore learn more efficiently. We use prioritized experience replay in Deep Q-Networks ({DQN}), a reinforcement learning algorithm that achieved human-level performance across many Atari games. {DQN} with prioritized experience replay achieves a new state-of-the-art, outperforming {DQN} with uniform replay on 41 out of 49 games.},
	number = {{arXiv}:1511.05952},
	publisher = {{arXiv}},
	author = {Schaul, Tom and Quan, John and Antonoglou, Ioannis and Silver, David},
	urldate = {2023-12-19},
	date = {2016-02-25},
	eprinttype = {arxiv},
	eprint = {1511.05952 [cs]},
	keywords = {Computer Science - Machine Learning},
	file = {arXiv Fulltext PDF:/Users/jonasprivat/Zotero/storage/L8YMD789/Schaul et al. - 2016 - Prioritized Experience Replay.pdf:application/pdf;arXiv.org Snapshot:/Users/jonasprivat/Zotero/storage/6YERYCNM/1511.html:text/html},
}


@article{spitzer_interaction_1970,
	title = {Interaction of Markov processes},
	volume = {5},
	issn = {0001-8708},
	url = {https://www.sciencedirect.com/science/article/pii/0001870870900344},
	doi = {10.1016/0001-8708(70)90034-4},
	pages = {246--290},
	number = {2},
	journaltitle = {Advances in Mathematics},
	shortjournal = {Advances in Mathematics},
	author = {Spitzer, Frank},
	urldate = {2023-12-19},
	date = {1970-10-01},
	file = {ScienceDirect Snapshot:/Users/jonasprivat/Zotero/storage/3QVN875L/0001870870900344.html:text/html;Spitzer - 1970 - Interaction of Markov processes.pdf:/Users/jonasprivat/Zotero/storage/T9BTAZ3E/Spitzer - 1970 - Interaction of Markov processes.pdf:application/pdf},
}

@article{goykolov_asymmetric_2007,
	title = {{ASYMMETRIC} {SIMPLE} {EXCLUSION} {PROCESS} {IN} {TWO} {DIMENSIONS}},
	author = {Goykolov, Dmytro},
	date = {2007},
	langid = {english},
	file = {Goykolov - 2007 - ASYMMETRIC SIMPLE EXCLUSION PROCESS IN TWO DIMENSI.pdf:/Users/jonasprivat/Zotero/storage/W6DHQIEB/Goykolov - 2007 - ASYMMETRIC SIMPLE EXCLUSION PROCESS IN TWO DIMENSI.pdf:application/pdf},
}

@article{blythe_nonequilibrium_2007,
	title = {Nonequilibrium Steady States of Matrix Product Form: A Solver's Guide},
	volume = {40},
	issn = {1751-8113, 1751-8121},
	url = {http://arxiv.org/abs/0706.1678},
	doi = {10.1088/1751-8113/40/46/R01},
	shorttitle = {Nonequilibrium Steady States of Matrix Product Form},
	abstract = {We consider the general problem of determining the steady state of stochastic nonequilibrium systems such as those that have been used to model (among other things) biological transport and traffic flow. We begin with a broad overview of this class of driven diffusive systems - which includes exclusion processes - focusing on interesting physical properties, such as shocks and phase transitions. We then turn our attention specifically to those models for which the exact distribution of microstates in the steady state can be expressed in a matrix product form. In addition to a gentle introduction to this matrix product approach, how it works and how it relates to similar constructions that arise in other physical contexts, we present a unified, pedagogical account of the various means by which the statistical mechanical calculations of macroscopic physical quantities are actually performed. We also review a number of more advanced topics, including nonequilibrium free energy functionals, the classification of exclusion processes involving multiple particle species, existence proofs of a matrix product state for a given model and more complicated variants of the matrix product state that allow various types of parallel dynamics to be handled. We conclude with a brief discussion of open problems for future research.},
	pages = {R333--R441},
	number = {46},
	journaltitle = {Journal of Physics A: Mathematical and Theoretical},
	shortjournal = {J. Phys. A: Math. Theor.},
	author = {Blythe, R. A. and Evans, M. R.},
	urldate = {2023-12-19},
	date = {2007-11-16},
	eprinttype = {arxiv},
	eprint = {0706.1678 [cond-mat]},
	keywords = {Condensed Matter - Statistical Mechanics},
	file = {arXiv Fulltext PDF:/Users/jonasprivat/Zotero/storage/76KEIGH7/Blythe and Evans - 2007 - Nonequilibrium Steady States of Matrix Product For.pdf:application/pdf;arXiv.org Snapshot:/Users/jonasprivat/Zotero/storage/IFFXQDZI/0706.html:text/html},
}

@article{daquila_monte_nodate,
	title = {Monte Carlo analysis of non-equilibrium steady states and relaxation kinetics in driven lattice gases},
	author = {Daquila, George Lawrence},
	langid = {english},
	file = {Daquila - Monte Carlo analysis of non-equilibrium steady sta.pdf:/Users/jonasprivat/Zotero/storage/NCRLPE2M/Daquila - Monte Carlo analysis of non-equilibrium steady sta.pdf:application/pdf},
}

@article{schutz_exact_1997,
	title = {Exact solution of the master equation for the asymmetric exclusion process},
	volume = {88},
	issn = {1572-9613},
	url = {https://doi.org/10.1007/BF02508478},
	doi = {10.1007/BF02508478},
	abstract = {Using the Bethe ansatz, we obtain the exact solution of the master equation for the totally asymmetric exclusion process on an infinite one-dimensional lattice. We derive explicit expressions for the conditional {probabilitiesP}(x1,...,{xN};t/y1,...,{yN}; 0) of {findingN} particles on lattices sitesx1,...,{xN} at timet with initial occupationy1,...,{yN} at timet=0.},
	pages = {427--445},
	number = {1},
	journaltitle = {Journal of Statistical Physics},
	shortjournal = {J Stat Phys},
	author = {Schütz, Gunter M.},
	urldate = {2023-12-22},
	date = {1997-07-01},
	langid = {english},
	keywords = {Asymmetric exclusion process, Bethe ansatz},
	file = {Full Text PDF:/Users/jonasprivat/Zotero/storage/JD4CHXRP/Schütz - 1997 - Exact solution of the master equation for the asym.pdf:application/pdf},
}

@article{macdonald_kinetics_1968,
	title = {Kinetics of biopolymerization on nucleic acid templates},
	volume = {6},
	rights = {Copyright © 1968 John Wiley \& Sons, Inc.},
	issn = {1097-0282},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/bip.1968.360060102},
	doi = {10.1002/bip.1968.360060102},
	abstract = {The kinetics of biopolymerization on nucleic acid templates is discussed. The model introduced allows for the simultaneous synthesis of several chains, of a given type, on a common template, e.g., the polyribosome situation. Each growth center [growing chain end plus enzyme(s)] moves one template site at a time, but blocks L adjacent sites. Solutions are found for the probability nj(t) that a template has a growing center that occupies the sites j — L + 1,…, j at time t. Two special sets of solutions are considered, the uniform-density solutions, for which nj(t) = n, and the more general steady-state solutions, for which dnj(t)/dt = 0. In the uniform-density case, there is an upper bound to the range of rates of polymerization that can occur. Corresponding to this maximum rate, there is one uniform solution. For a polymerization rate less than this maximum, there are two uniform solutions that give the same rate. In the steady-state case, only L = 1 is discussed. For a steady-state polymerization rate less than the maximum uniform-density rate, the steady-state solutions consist of either one or two regions of nearly uniform density, with the density value(s) assumed in the uniform region(s) being either or both of the uniform-density solutions corresponding to that polymerization rate. For a steady-state polymerization rate equal to or slightly larger than the maximum uniform-density rate, the steady-state solutions are nearly uniform to the single uniform-density solution for the maximum rate. The boundary conditions (rate of initiation and rate, of release of completed chains from the template) govern the choice among the possible solutions, i.e., determine the region(s) of uniformity and the value(s) assumed in the uniform region(s).},
	pages = {1--25},
	number = {1},
	journaltitle = {Biopolymers},
	author = {{MacDonald}, Carolyn T. and Gibbs, Julian H. and Pipkin, Allen C.},
	urldate = {2023-12-22},
	date = {1968},
	langid = {english},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/bip.1968.360060102},
	file = {Snapshot:/Users/jonasprivat/Zotero/storage/KUBQKKQN/bip.1968.html:text/html},
}


@software{maertens_smarttasep_github_2023,
	title = {jonasmaertens/{TASEP}},
	rights = {{MIT}},
	url = {https://github.com/jonasmaertens/TASEP},
	abstract = {Implements a Totally Asymmetric Simple Exclusion Process ({TASEP}) using reinforcement learning ({RL}) agents},
	author = {Märtens, Jonas},
	urldate = {2023-12-23},
	date = {2023-12-22},
	note = {original-date: 2023-10-05T16:07:08Z},
	keywords = {reinforcement-learning, simple-exclusion-process, tasep},
}


@inproceedings{lam_numba_2015,
	location = {New York, {NY}, {USA}},
	title = {Numba: a {LLVM}-based Python {JIT} compiler},
	isbn = {978-1-4503-4005-2},
	url = {https://dl.acm.org/doi/10.1145/2833157.2833162},
	doi = {10.1145/2833157.2833162},
	series = {{LLVM} '15},
	shorttitle = {Numba},
	abstract = {Dynamic, interpreted languages, like Python, are attractive for domain-experts and scientists experimenting with new ideas. However, the performance of the interpreter is often a barrier when scaling to larger data sets. This paper presents a just-in-time compiler for Python that focuses in scientific and array-oriented computing. Starting with the simple syntax of Python, Numba compiles a subset of the language into efficient machine code that is comparable in performance to a traditional compiled language. In addition, we share our experience in building a {JIT} compiler using {LLVM}[1].},
	pages = {1--6},
	booktitle = {Proceedings of the Second Workshop on the {LLVM} Compiler Infrastructure in {HPC}},
	publisher = {Association for Computing Machinery},
	author = {Lam, Siu Kwan and Pitrou, Antoine and Seibert, Stanley},
	urldate = {2023-12-24},
	date = {2015-11-15},
	keywords = {compiler, {LLVM}, Python},
	file = {Full Text PDF:/Users/jonasprivat/Zotero/storage/FJQURBAY/Lam et al. - 2015 - Numba a LLVM-based Python JIT compiler.pdf:application/pdf},
}

@misc{brockman_openai_2016,
	title = {{OpenAI} Gym},
	url = {http://arxiv.org/abs/1606.01540},
	doi = {10.48550/arXiv.1606.01540},
	abstract = {{OpenAI} Gym is a toolkit for reinforcement learning research. It includes a growing collection of benchmark problems that expose a common interface, and a website where people can share their results and compare the performance of algorithms. This whitepaper discusses the components of {OpenAI} Gym and the design decisions that went into the software.},
	number = {{arXiv}:1606.01540},
	publisher = {{arXiv}},
	author = {Brockman, Greg and Cheung, Vicki and Pettersson, Ludwig and Schneider, Jonas and Schulman, John and Tang, Jie and Zaremba, Wojciech},
	urldate = {2023-12-28},
	date = {2016-06-05},
	eprinttype = {arxiv},
	eprint = {1606.01540 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
	file = {arXiv Fulltext PDF:/Users/jonasprivat/Zotero/storage/LAP2CU8N/Brockman et al. - 2016 - OpenAI Gym.pdf:application/pdf;arXiv.org Snapshot:/Users/jonasprivat/Zotero/storage/5GR2VLJD/1606.html:text/html},
}

@misc{bou_torchrl_2023,
	title = {{TorchRL}: A data-driven decision-making library for {PyTorch}},
	url = {http://arxiv.org/abs/2306.00577},
	doi = {10.48550/arXiv.2306.00577},
	shorttitle = {{TorchRL}},
	abstract = {{PyTorch} has ascended as a premier machine learning framework, yet it lacks a native and comprehensive library for decision and control tasks suitable for large development teams dealing with complex real-world data and environments. To address this issue, we propose {TorchRL}, a generalistic control library for {PyTorch} that provides well-integrated, yet standalone components. We introduce a new and flexible {PyTorch} primitive, the {TensorDict}, which facilitates streamlined algorithm development across the many branches of Reinforcement Learning ({RL}) and control. We provide a detailed description of the building blocks and an extensive overview of the library across domains and tasks. Finally, we experimentally demonstrate its reliability and flexibility and show comparative benchmarks to demonstrate its computational efficiency. {TorchRL} fosters long-term support and is publicly available on {GitHub} for greater reproducibility and collaboration within the research community. The code is open-sourced on {GitHub}.},
	number = {{arXiv}:2306.00577},
	publisher = {{arXiv}},
	author = {Bou, Albert and Bettini, Matteo and Dittert, Sebastian and Kumar, Vikash and Sodhani, Shagun and Yang, Xiaomeng and De Fabritiis, Gianni and Moens, Vincent},
	urldate = {2024-01-01},
	date = {2023-11-27},
	eprinttype = {arxiv},
	eprint = {2306.00577 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
	file = {arXiv Fulltext PDF:/Users/jonasprivat/Zotero/storage/Y6BKRQES/Bou et al. - 2023 - TorchRL A data-driven decision-making library for.pdf:application/pdf;arXiv.org Snapshot:/Users/jonasprivat/Zotero/storage/MRIYY4C5/2306.html:text/html},
}


@misc{ruder_overview_2017,
	title = {An overview of gradient descent optimization algorithms},
	url = {http://arxiv.org/abs/1609.04747},
	doi = {10.48550/arXiv.1609.04747},
	abstract = {Gradient descent optimization algorithms, while increasingly popular, are often used as black-box optimizers, as practical explanations of their strengths and weaknesses are hard to come by. This article aims to provide the reader with intuitions with regard to the behaviour of different algorithms that will allow her to put them to use. In the course of this overview, we look at different variants of gradient descent, summarize challenges, introduce the most common optimization algorithms, review architectures in a parallel and distributed setting, and investigate additional strategies for optimizing gradient descent.},
	number = {{arXiv}:1609.04747},
	publisher = {{arXiv}},
	author = {Ruder, Sebastian},
	urldate = {2024-01-01},
	date = {2017-06-15},
	eprinttype = {arxiv},
	eprint = {1609.04747 [cs]},
	keywords = {Computer Science - Machine Learning},
	file = {arXiv Fulltext PDF:/Users/jonasprivat/Zotero/storage/FTHBND2H/Ruder - 2017 - An overview of gradient descent optimization algor.pdf:application/pdf;arXiv.org Snapshot:/Users/jonasprivat/Zotero/storage/JG2CRJEZ/1609.html:text/html},
}

@misc{kingma_adam_2017,
	title = {Adam: A Method for Stochastic Optimization},
	url = {http://arxiv.org/abs/1412.6980},
	doi = {10.48550/arXiv.1412.6980},
	shorttitle = {Adam},
	abstract = {We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss {AdaMax}, a variant of Adam based on the infinity norm.},
	number = {{arXiv}:1412.6980},
	publisher = {{arXiv}},
	author = {Kingma, Diederik P. and Ba, Jimmy},
	urldate = {2024-01-01},
	date = {2017-01-29},
	eprinttype = {arxiv},
	eprint = {1412.6980 [cs]},
	keywords = {Computer Science - Machine Learning},
	file = {arXiv Fulltext PDF:/Users/jonasprivat/Zotero/storage/DLT28QMX/Kingma and Ba - 2017 - Adam A Method for Stochastic Optimization.pdf:application/pdf;arXiv.org Snapshot:/Users/jonasprivat/Zotero/storage/3IR4SYRN/1412.html:text/html},
}

@misc{loshchilov_decoupled_2019,
	title = {Decoupled Weight Decay Regularization},
	url = {http://arxiv.org/abs/1711.05101},
	doi = {10.48550/arXiv.1711.05101},
	abstract = {L\$\_2\$ regularization and weight decay regularization are equivalent for standard stochastic gradient descent (when rescaled by the learning rate), but as we demonstrate this is {\textbackslash}emph\{not\} the case for adaptive gradient algorithms, such as Adam. While common implementations of these algorithms employ L\$\_2\$ regularization (often calling it "weight decay" in what may be misleading due to the inequivalence we expose), we propose a simple modification to recover the original formulation of weight decay regularization by {\textbackslash}emph\{decoupling\} the weight decay from the optimization steps taken w.r.t. the loss function. We provide empirical evidence that our proposed modification (i) decouples the optimal choice of weight decay factor from the setting of the learning rate for both standard {SGD} and Adam and (ii) substantially improves Adam's generalization performance, allowing it to compete with {SGD} with momentum on image classification datasets (on which it was previously typically outperformed by the latter). Our proposed decoupled weight decay has already been adopted by many researchers, and the community has implemented it in {TensorFlow} and {PyTorch}; the complete source code for our experiments is available at https://github.com/loshchil/{AdamW}-and-{SGDW}},
	number = {{arXiv}:1711.05101},
	publisher = {{arXiv}},
	author = {Loshchilov, Ilya and Hutter, Frank},
	urldate = {2024-01-01},
	date = {2019-01-04},
	eprinttype = {arxiv},
	eprint = {1711.05101 [cs, math]},
	keywords = {Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing, Mathematics - Optimization and Control},
	file = {arXiv Fulltext PDF:/Users/jonasprivat/Zotero/storage/867PAAAH/Loshchilov and Hutter - 2019 - Decoupled Weight Decay Regularization.pdf:application/pdf;arXiv.org Snapshot:/Users/jonasprivat/Zotero/storage/HBG7DESM/1711.html:text/html},
}

@article{parker-holder_automated_2022,
	title = {Automated Reinforcement Learning ({AutoRL}): A Survey and Open Problems},
	volume = {74},
	issn = {1076-9757},
	url = {http://arxiv.org/abs/2201.03916},
	doi = {10.1613/jair.1.13596},
	shorttitle = {Automated Reinforcement Learning ({AutoRL})},
	abstract = {The combination of Reinforcement Learning ({RL}) with deep learning has led to a series of impressive feats, with many believing (deep) {RL} provides a path towards generally capable agents. However, the success of {RL} agents is often highly sensitive to design choices in the training process, which may require tedious and error-prone manual tuning. This makes it challenging to use {RL} for new problems, while also limits its full potential. In many other areas of machine learning, {AutoML} has shown it is possible to automate such design choices and has also yielded promising initial results when applied to {RL}. However, Automated Reinforcement Learning ({AutoRL}) involves not only standard applications of {AutoML} but also includes additional challenges unique to {RL}, that naturally produce a different set of methods. As such, {AutoRL} has been emerging as an important area of research in {RL}, providing promise in a variety of applications from {RNA} design to playing games such as Go. Given the diversity of methods and environments considered in {RL}, much of the research has been conducted in distinct subfields, ranging from meta-learning to evolution. In this survey we seek to unify the field of {AutoRL}, we provide a common taxonomy, discuss each area in detail and pose open problems which would be of interest to researchers going forward.},
	pages = {517--568},
	journaltitle = {Journal of Artificial Intelligence Research},
	shortjournal = {jair},
	author = {Parker-Holder, Jack and Rajan, Raghu and Song, Xingyou and Biedenkapp, André and Miao, Yingjie and Eimer, Theresa and Zhang, Baohe and Nguyen, Vu and Calandra, Roberto and Faust, Aleksandra and Hutter, Frank and Lindauer, Marius},
	urldate = {2024-01-07},
	date = {2022-06-01},
	eprinttype = {arxiv},
	eprint = {2201.03916 [cs]},
	keywords = {68T01, Computer Science - Machine Learning, I.2.6},
	file = {arXiv Fulltext PDF:/Users/jonasprivat/Zotero/storage/T84LV74A/Parker-Holder et al. - 2022 - Automated Reinforcement Learning (AutoRL) A Surve.pdf:application/pdf;arXiv.org Snapshot:/Users/jonasprivat/Zotero/storage/7FZ5MD6T/2201.html:text/html},
}

@online{noauthor_automl_nodate,
	title = {{AutoML} {\textbar} {AutoRL}: {AutoML} for {RL}},
	url = {https://www.automl.org/blog-autorl/},
	shorttitle = {{AutoML} {\textbar} {AutoRL}},
	urldate = {2024-01-07},
	langid = {english},
	file = {Snapshot:/Users/jonasprivat/Zotero/storage/BRUQJ4H2/blog-autorl.html:text/html},
}

@misc{henderson_deep_2019,
	title = {Deep Reinforcement Learning that Matters},
	url = {http://arxiv.org/abs/1709.06560},
	doi = {10.48550/arXiv.1709.06560},
	abstract = {In recent years, significant progress has been made in solving challenging problems across various domains using deep reinforcement learning ({RL}). Reproducing existing work and accurately judging the improvements offered by novel methods is vital to sustaining this progress. Unfortunately, reproducing results for state-of-the-art deep {RL} methods is seldom straightforward. In particular, non-determinism in standard benchmark environments, combined with variance intrinsic to the methods, can make reported results tough to interpret. Without significance metrics and tighter standardization of experimental reporting, it is difficult to determine whether improvements over the prior state-of-the-art are meaningful. In this paper, we investigate challenges posed by reproducibility, proper experimental techniques, and reporting procedures. We illustrate the variability in reported metrics and results when comparing against common baselines and suggest guidelines to make future results in deep {RL} more reproducible. We aim to spur discussion about how to ensure continued progress in the field by minimizing wasted effort stemming from results that are non-reproducible and easily misinterpreted.},
	number = {{arXiv}:1709.06560},
	publisher = {{arXiv}},
	author = {Henderson, Peter and Islam, Riashat and Bachman, Philip and Pineau, Joelle and Precup, Doina and Meger, David},
	urldate = {2024-01-07},
	date = {2019-01-29},
	eprinttype = {arxiv},
	eprint = {1709.06560 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:/Users/jonasprivat/Zotero/storage/ACZCANX2/Henderson et al. - 2019 - Deep Reinforcement Learning that Matters.pdf:application/pdf;arXiv.org Snapshot:/Users/jonasprivat/Zotero/storage/QBGE9GIX/1709.html:text/html},
}


@misc{andrychowicz_what_2020,
	title = {What Matters In On-Policy Reinforcement Learning? A Large-Scale Empirical Study},
	url = {http://arxiv.org/abs/2006.05990},
	doi = {10.48550/arXiv.2006.05990},
	shorttitle = {What Matters In On-Policy Reinforcement Learning?},
	abstract = {In recent years, on-policy reinforcement learning ({RL}) has been successfully applied to many different continuous control tasks. While {RL} algorithms are often conceptually simple, their state-of-the-art implementations take numerous low- and high-level design decisions that strongly affect the performance of the resulting agents. Those choices are usually not extensively discussed in the literature, leading to discrepancy between published descriptions of algorithms and their implementations. This makes it hard to attribute progress in {RL} and slows down overall progress [Engstrom'20]. As a step towards filling that gap, we implement {\textgreater}50 such ``choices'' in a unified on-policy {RL} framework, allowing us to investigate their impact in a large-scale empirical study. We train over 250'000 agents in five continuous control environments of different complexity and provide insights and practical recommendations for on-policy training of {RL} agents.},
	number = {{arXiv}:2006.05990},
	publisher = {{arXiv}},
	author = {Andrychowicz, Marcin and Raichuk, Anton and Stańczyk, Piotr and Orsini, Manu and Girgin, Sertan and Marinier, Raphael and Hussenot, Léonard and Geist, Matthieu and Pietquin, Olivier and Michalski, Marcin and Gelly, Sylvain and Bachem, Olivier},
	urldate = {2024-01-09},
	date = {2020-06-10},
	eprinttype = {arxiv},
	eprint = {2006.05990 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:/Users/jonasprivat/Zotero/storage/T4NF6VNX/Andrychowicz et al. - 2020 - What Matters In On-Policy Reinforcement Learning .pdf:application/pdf;arXiv.org Snapshot:/Users/jonasprivat/Zotero/storage/8MY5KH94/2006.html:text/html},
}

@misc{engstrom_implementation_2020,
	title = {Implementation Matters in Deep Policy Gradients: A Case Study on {PPO} and {TRPO}},
	url = {http://arxiv.org/abs/2005.12729},
	doi = {10.48550/arXiv.2005.12729},
	shorttitle = {Implementation Matters in Deep Policy Gradients},
	abstract = {We study the roots of algorithmic progress in deep policy gradient algorithms through a case study on two popular algorithms: Proximal Policy Optimization ({PPO}) and Trust Region Policy Optimization ({TRPO}). Specifically, we investigate the consequences of "code-level optimizations:" algorithm augmentations found only in implementations or described as auxiliary details to the core algorithm. Seemingly of secondary importance, such optimizations turn out to have a major impact on agent behavior. Our results show that they (a) are responsible for most of {PPO}'s gain in cumulative reward over {TRPO}, and (b) fundamentally change how {RL} methods function. These insights show the difficulty and importance of attributing performance gains in deep reinforcement learning. Code for reproducing our results is available at https://github.com/{MadryLab}/implementation-matters .},
	number = {{arXiv}:2005.12729},
	publisher = {{arXiv}},
	author = {Engstrom, Logan and Ilyas, Andrew and Santurkar, Shibani and Tsipras, Dimitris and Janoos, Firdaus and Rudolph, Larry and Madry, Aleksander},
	urldate = {2024-01-09},
	date = {2020-05-25},
	eprinttype = {arxiv},
	eprint = {2005.12729 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Computer Science - Robotics, Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:/Users/jonasprivat/Zotero/storage/PUR68SVT/Engstrom et al. - 2020 - Implementation Matters in Deep Policy Gradients A.pdf:application/pdf;arXiv.org Snapshot:/Users/jonasprivat/Zotero/storage/HPCAM8NU/2005.html:text/html},
}



@article{kaspar_rise_2021,
	title = {The rise of intelligent matter},
	volume = {594},
	rights = {2021 Springer Nature Limited},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/s41586-021-03453-y},
	doi = {10.1038/s41586-021-03453-y},
	abstract = {Artificial intelligence ({AI}) is accelerating the development of unconventional computing paradigms inspired by the abilities and energy efficiency of the brain. The human brain excels especially in computationally intensive cognitive tasks, such as pattern recognition and classification. A long-term goal is de-centralized neuromorphic computing, relying on a network of distributed cores to mimic the massive parallelism of the brain, thus rigorously following a nature-inspired approach for information processing. Through the gradual transformation of interconnected computing blocks into continuous computing tissue, the development of advanced forms of matter exhibiting basic features of intelligence can be envisioned, able to learn and process information in a delocalized manner. Such intelligent matter would interact with the environment by receiving and responding to external stimuli, while internally adapting its structure to enable the distribution and storage (as memory) of information. We review progress towards implementations of intelligent matter using molecular systems, soft materials or solid-state materials, with respect to applications in soft robotics, the development of adaptive artificial skins and distributed neuromorphic computing.},
	pages = {345--355},
	number = {7863},
	journaltitle = {Nature},
	author = {Kaspar, C. and Ravoo, B. J. and van der Wiel, W. G. and Wegner, S. V. and Pernice, W. H. P.},
	urldate = {2024-01-13},
	date = {2021-06},
	langid = {english},
	note = {Number: 7863
Publisher: Nature Publishing Group},
	keywords = {Composites, Molecular self-assembly, Nanoscale biophysics},
	file = {Full Text PDF:/Users/jonasprivat/Zotero/storage/3D27J8VZ/Kaspar et al. - 2021 - The rise of intelligent matter.pdf:application/pdf},
}

@article{fodor_how_2016,
	title = {How far from equilibrium is active matter?},
	volume = {117},
	issn = {0031-9007, 1079-7114},
	url = {http://arxiv.org/abs/1604.00953},
	doi = {10.1103/PhysRevLett.117.038103},
	abstract = {Active matter systems are driven out of thermal equilibrium by a lack of generalized Stokes-Einstein relation between injection and dissipation of energy at the microscopic scale. We consider such a system of interacting particles, propelled by persistent noises, and show that, at small but finite persistence time, their dynamics still satisfy a time-reversal symmetry. To do so, we compute perturbatively their steady-state measure and show that, for short persistent times, the entropy production rate vanishes. This endows such systems with an effective Fluctuation-Dissipation theorem akin to that of thermal equilibrium systems. Last we show how interacting particle systems with viscous drags and correlated noises can be seen as in equilibrium with a visco-elastic bath but driven out of equilibrium by non-conservative forces, hence providing an energetic insight on the departure of active systems from equilibrium.},
	pages = {038103},
	number = {3},
	journaltitle = {Physical Review Letters},
	shortjournal = {Phys. Rev. Lett.},
	author = {Fodor, Étienne and Nardini, Cesare and Cates, Mike E. and Tailleur, Julien and Visco, Paolo and van Wijland, Frédéric},
	urldate = {2024-01-13},
	date = {2016-07-13},
	eprinttype = {arxiv},
	eprint = {1604.00953 [cond-mat]},
	keywords = {Condensed Matter - Soft Condensed Matter, Condensed Matter - Statistical Mechanics},
	file = {arXiv Fulltext PDF:/Users/jonasprivat/Zotero/storage/6XQYKU5D/Fodor et al. - 2016 - How far from equilibrium is active matter.pdf:application/pdf;arXiv.org Snapshot:/Users/jonasprivat/Zotero/storage/7GMXV2PQ/1604.html:text/html},
}

@article{popkin_physics_2016,
	title = {The physics of life},
	volume = {529},
	rights = {2016 Springer Nature Limited},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/529016a},
	doi = {10.1038/529016a},
	abstract = {From flocking birds to swarming molecules, physicists are seeking to understand 'active matter' — and looking for a fundamental theory of the living world.},
	pages = {16--18},
	number = {7584},
	journaltitle = {Nature},
	author = {Popkin, Gabriel},
	urldate = {2024-01-13},
	date = {2016-01-01},
	langid = {english},
	note = {Number: 7584
Publisher: Nature Publishing Group},
	keywords = {Biophysics, Cell biology, Chemical biology, Fluid dynamics},
	file = {Full Text PDF:/Users/jonasprivat/Zotero/storage/SUFY5MD5/Popkin - 2016 - The physics of life.pdf:application/pdf;Snapshot:/Users/jonasprivat/Zotero/storage/M248AYE6/529016a.html:text/html},
}

@article{cichos_machine_2020,
	title = {Machine learning for active matter},
	volume = {2},
	rights = {2020 The Author(s), under exclusive licence to Springer Nature Limited},
	issn = {2522-5839},
	url = {https://www.nature.com/articles/s42256-020-0146-9},
	doi = {10.1038/s42256-020-0146-9},
	abstract = {The availability of large datasets has boosted the application of machine learning in many fields and is now starting to shape active-matter research as well. Machine learning techniques have already been successfully applied to active-matter data—for example, deep neural networks to analyse images and track objects, and recurrent nets and random forests to analyse time series. Yet machine learning can also help to disentangle the complexity of biological active matter, helping, for example, to establish a relation between genetic code and emergent bacterial behaviour, to find navigation strategies in complex environments, and to map physical cues to animal behaviours. In this Review, we highlight the current state of the art in the application of machine learning to active matter and discuss opportunities and challenges that are emerging. We also emphasize how active matter and machine learning can work together for mutual benefit.},
	pages = {94--103},
	number = {2},
	journaltitle = {Nature Machine Intelligence},
	shortjournal = {Nat Mach Intell},
	author = {Cichos, Frank and Gustavsson, Kristian and Mehlig, Bernhard and Volpe, Giovanni},
	urldate = {2024-01-13},
	date = {2020-02},
	langid = {english},
	note = {Number: 2
Publisher: Nature Publishing Group},
	keywords = {Computational platforms and environments, Materials science, Mathematics and computing},
}

@inproceedings{rubenstein_kilobot_2012,
	title = {Kilobot: A low cost scalable robot system for collective behaviors},
	url = {https://ieeexplore.ieee.org/document/6224638},
	doi = {10.1109/ICRA.2012.6224638},
	shorttitle = {Kilobot},
	abstract = {In current robotics research there is a vast body of work on algorithms and control methods for groups of decentralized cooperating robots, called a swarm or collective. These algorithms are generally meant to control collectives of hundreds or even thousands of robots; however, for reasons of cost, time, or complexity, they are generally validated in simulation only, or on a group of a few tens of robots. To address this issue, this paper presents Kilobot, a low-cost robot designed to make testing collective algorithms on hundreds or thousands of robots accessible to robotics researchers. To enable the possibility of large Kilobot collectives where the number of robots is an order of magnitude larger than the largest that exist today, each robot is made with only \$14 worth of parts and takes 5 minutes to assemble. Furthermore, the robot design allows a single user to easily operate a large Kilobot collective, such as programming, powering on, and charging all robots, which would be difficult or impossible to do with many existing robotic systems.},
	eventtitle = {2012 {IEEE} International Conference on Robotics and Automation},
	pages = {3293--3298},
	booktitle = {2012 {IEEE} International Conference on Robotics and Automation},
	author = {Rubenstein, Michael and Ahler, Christian and Nagpal, Radhika},
	urldate = {2024-01-13},
	date = {2012-05},
	note = {{ISSN}: 1050-4729},
	file = {IEEE Xplore Abstract Record:/Users/jonasprivat/Zotero/storage/HWSFH6YE/6224638.html:text/html;Submitted Version:/Users/jonasprivat/Zotero/storage/SLBFX3B9/Rubenstein et al. - 2012 - Kilobot A low cost scalable robot system for coll.pdf:application/pdf},
}

@article{bonabeau_agent-based_2002,
	title = {Agent-based modeling: Methods and techniques for simulating human systems},
	volume = {99},
	url = {https://www.pnas.org/doi/10.1073/pnas.082080899},
	doi = {10.1073/pnas.082080899},
	shorttitle = {Agent-based modeling},
	abstract = {Agent-based modeling is a powerful simulation modeling technique that has seen a number of applications in the last few years, including applications to real-world business problems. After the basic principles of agent-based simulation are briefly introduced, its four areas of application are discussed by using real-world applications: flow simulation, organizational simulation, market simulation, and diffusion simulation. For each category, one or several business applications are described and analyzed.},
	pages = {7280--7287},
	issue = {suppl\_3},
	journaltitle = {Proceedings of the National Academy of Sciences},
	author = {Bonabeau, Eric},
	urldate = {2024-01-13},
	date = {2002-05-14},
	note = {Publisher: Proceedings of the National Academy of Sciences},
	file = {Full Text PDF:/Users/jonasprivat/Zotero/storage/IM9P8V3Q/Bonabeau - 2002 - Agent-based modeling Methods and techniques for s.pdf:application/pdf},
}

@article{pomorski_thermodynamics_2023,
	title = {Thermodynamics in Stochastic Conway’s Game of Life},
	volume = {8},
	rights = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2410-3896},
	url = {https://www.mdpi.com/2410-3896/8/2/47},
	doi = {10.3390/condmat8020047},
	abstract = {Cellular automata can simulate many complex physical phenomena using the power of simple rules. The presented methodological platform expresses the concept of programmable matter, of which Newton’s laws of motion are an example. Energy is introduced as the equivalent of the “Game of Life” mass, which can be treated as the first level of approximation. The temperature presence and propagation was calculated for various lattice topologies and boundary conditions, using the Shannon entropy measure. This study provides strong evidence that, despite the principle of mass and energy conservation not being fulfilled, the entropy, mass distribution, and temperature approach thermodynamic equilibrium. In addition, the described cellular automaton system transitions from a positive to a negative temperature, which stabilizes and can be treated as a signature of a system in equilibrium. The system dynamics is presented for a few species of cellular automata competing for maximum presence on a given lattice with different boundary conditions.},
	pages = {47},
	number = {2},
	journaltitle = {Condensed Matter},
	author = {Pomorski, Krzysztof and Kotula, Dariusz},
	urldate = {2024-01-13},
	date = {2023-06},
	langid = {english},
	note = {Number: 2
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {cellular automata, cellular automaton species, diffusion, entropy, Stochastic Conway’s Game of Life, temperature for Conway’s Game of Life},
	file = {Full Text PDF:/Users/jonasprivat/Zotero/storage/KQCBNHRD/Pomorski and Kotula - 2023 - Thermodynamics in Stochastic Conway’s Game of Life.pdf:application/pdf},
}

@incollection{gotts_emergent_2010,
	location = {London},
	title = {Emergent Complexity in Conway’s Game of Life},
	isbn = {978-1-84996-217-9},
	url = {https://doi.org/10.1007/978-1-84996-217-9_20},
	abstract = {It is shown that both small, finite patterns and random infinite very low density (“sparse”) arrays of the Game of Life can produce emergent structures and processes of great complexity, through ramifying feedback networks and cross-scale interactions. The implications are discussed: it is proposed that analogous networks and interactions may have been precursors to natural selection in the real world.},
	pages = {389--436},
	booktitle = {Game of Life Cellular Automata},
	publisher = {Springer},
	author = {Gotts, Nick},
	editor = {Adamatzky, Andrew},
	urldate = {2024-01-13},
	date = {2010},
	langid = {english},
	doi = {10.1007/978-1-84996-217-9_20},
	keywords = {Cellular Automaton, Feedback Network, Global Density, Growth Cluster, Quadratic Growth},
}


@inreference{wiki_statistical_2024,
	title = {Statistical mechanics},
	rights = {Creative Commons Attribution-{ShareAlike} License},
	url = {https://en.wikipedia.org/w/index.php?title=Statistical_mechanics&oldid=1194581857},
	abstract = {In physics, statistical mechanics is a mathematical framework that applies statistical methods and probability theory to large assemblies of microscopic entities. It does not assume or postulate any natural laws, but explains the macroscopic behavior of nature from the behavior of such ensembles.
Sometimes called statistical physics or statistical thermodynamics, its applications include many problems in the fields of physics, biology, chemistry, and neuroscience. Its main purpose is to clarify the properties of matter in aggregate, in terms of physical laws governing atomic motion.Statistical mechanics arose out of the development of classical thermodynamics, a field for which it was successful in explaining macroscopic physical properties—such as temperature, pressure, and heat capacity—in terms of microscopic parameters that fluctuate about average values and are characterized by probability distributions.
The founding of the field of statistical mechanics is generally credited to three physicists:

Ludwig Boltzmann, who developed the fundamental interpretation of entropy in terms of a collection of microstates
James Clerk Maxwell, who developed models of probability distribution of such states
Josiah Willard Gibbs, who coined the name of the field in 1884While classical thermodynamics is primarily concerned with thermodynamic equilibrium, statistical mechanics has been applied in non-equilibrium statistical mechanics to the issues of microscopically modeling the speed of irreversible processes that are driven by imbalances. Examples of such processes include chemical reactions and flows of particles and heat. The fluctuation–dissipation theorem is the basic knowledge obtained from applying non-equilibrium statistical mechanics to study the simplest non-equilibrium situation of a steady state current flow in a system of many particles.},
	booktitle = {Wikipedia},
	urldate = {2024-01-13},
	date = {2024-01-09},
	langid = {english},
	note = {Page Version {ID}: 1194581857},
	file = {Snapshot:/Users/jonasprivat/Zotero/storage/RVVBGQ7T/Statistical_mechanics.html:text/html},
}


@article{fernandez-carames_towards_2018,
	title = {Towards The Internet of Smart Clothing: A Review on {IoT} Wearables and Garments for Creating Intelligent Connected E-Textiles},
	volume = {7},
	rights = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2079-9292},
	url = {https://www.mdpi.com/2079-9292/7/12/405},
	doi = {10.3390/electronics7120405},
	shorttitle = {Towards The Internet of Smart Clothing},
	abstract = {Technology has become ubiquitous, it is all around us and is becoming part of us. Togetherwith the rise of the Internet of Things ({IoT}) paradigm and enabling technologies (e.g., Augmented Reality ({AR}), Cyber-Physical Systems, Artificial Intelligence ({AI}), blockchain or edge computing), smart wearables and {IoT}-based garments can potentially have a lot of influence by harmonizing functionality and the delight created by fashion. Thus, smart clothes look for a balance among fashion, engineering, interaction, user experience, cybersecurity, design and science to reinvent technologies that can anticipate needs and desires. Nowadays, the rapid convergence of textile and electronics is enabling the seamless and massive integration of sensors into textiles and the development of conductive yarn. The potential of smart fabrics, which can communicate with smartphones to process biometric information such as heart rate, temperature, breathing, stress, movement, acceleration, or even hormone levels, promises a new era for retail. This article reviews the main requirements for developing smart {IoT}-enabled garments and shows smart clothing potential impact on business models in the medium-term. Specifically, a global {IoT} architecture is proposed, the main types and components of smart {IoT} wearables and garments are presented, their main requirements are analyzed and some of the most recent smart clothing applications are studied. In this way, this article reviews the past and present of smart garments in order to provide guidelines for the future developers of a network where garments will be connected like other {IoT} objects: the Internet of Smart Clothing.},
	pages = {405},
	number = {12},
	journaltitle = {Electronics},
	author = {Fernández-Caramés, Tiago M. and Fraga-Lamas, Paula},
	urldate = {2024-01-13},
	date = {2018-12},
	langid = {english},
	note = {Number: 12
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {biometrics, blockchain, e-textiles, electronic textiles, Industry 4.0, Internet of Things, {IoT}, sensors, smart clothing, smart garments, wearables},
	file = {Full Text PDF:/Users/jonasprivat/Zotero/storage/QGFM2EEY/Fernández-Caramés and Fraga-Lamas - 2018 - Towards The Internet of Smart Clothing A Review o.pdf:application/pdf},
}


@article{balasubramanian_brain_2021,
	title = {Brain power},
	volume = {118},
	issn = {0027-8424},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8364152/},
	doi = {10.1073/pnas.2107022118},
	pages = {e2107022118},
	number = {32},
	journaltitle = {Proceedings of the National Academy of Sciences of the United States of America},
	shortjournal = {Proc Natl Acad Sci U S A},
	author = {Balasubramanian, Vijay},
	urldate = {2024-01-13},
	date = {2021-08-10},
	pmid = {34341108},
	pmcid = {PMC8364152},
	file = {PubMed Central Full Text PDF:/Users/jonasprivat/Zotero/storage/NAWI3R6I/Balasubramanian - 2021 - Brain power.pdf:application/pdf},
}


@online{bostondynamics_spot_2024,
	title = {Spot},
	url = {https://bostondynamics.com/products/spot/},
	abstract = {Spot is changing how organizations monitor and operate their sites. Improve safety and efficiency with agile mobile robot solutions from Boston Dynamics.},
	titleaddon = {Boston Dynamics},
	urldate = {2024-01-14},
	langid = {american},
	file = {Snapshot:/Users/jonasprivat/Zotero/storage/RXMJ8M79/spot.html:text/html},
}


@article{koval_experimental_2022,
	title = {Experimental evaluation of autonomous map-based Spot navigation in confined environments},
	volume = {2},
	issn = {2667-3797},
	url = {https://www.sciencedirect.com/science/article/pii/S2667379722000018},
	doi = {10.1016/j.birob.2022.100035},
	abstract = {In this article, we address the task of experimental evaluation of autonomous map-based navigation of a Boston Dynamics Spot quadruped robot in confined environments equipped with the developed autonomy package that incorporates a 3D lidar, an {IMU}, and an onboard computer. For that, we propose an integrated software and hardware system that is considered as an enabler for robot localization and risk-aware path planning, based on the known map. The system design itself is modular and incorporates the perception capabilities required for autonomous navigation. The Spot robot first is utilized to build the offline map of the environment by utilizing the Google Cartographer simultaneous localization and mapping ({SLAM}) package. During the next step, the online environmental information from the autonomy package sensors and the offline map are provided to the onboard computer to localize the robot on the known map by utilizing means provided by Cartographer. Finally, the occupancy information is provided to the online grid-based path planner that generates risk-aware paths. The extensive experimental evaluation of the proposed system is performed in corridors and {SubT} environments.},
	pages = {100035},
	number = {1},
	journaltitle = {Biomimetic Intelligence and Robotics},
	shortjournal = {Biomimetic Intelligence and Robotics},
	author = {Koval, Anton and Karlsson, Samuel and Nikolakopoulos, George},
	urldate = {2024-01-14},
	date = {2022-03-01},
	keywords = {3D lidar, Autonomy package, Map-based navigation, Spot, {SubT}},
	file = {ScienceDirect Snapshot:/Users/jonasprivat/Zotero/storage/D8FWIYBT/S2667379722000018.html:text/html},
}

@inreference{wiki_collective_2024,
	title = {Collective animal behavior},
	rights = {Creative Commons Attribution-{ShareAlike} License},
	url = {https://en.wikipedia.org/w/index.php?title=Collective_animal_behavior&oldid=1193934250},
	abstract = {Collective animal behaviour is a form of social behavior involving the coordinated behavior of large groups of similar animals as well as emergent properties of these groups. This can include the costs and benefits of group membership, the transfer of information, decision-making process, locomotion and synchronization of the group. Studying the principles of collective animal behavior has relevance to human engineering problems through the philosophy of biomimetics. For instance, determining the rules by which an individual animal navigates relative to its neighbors in a group can lead to advances in the deployment and control of groups of swimming or flying micro-robots such as {UAVs} (Unmanned Aerial Vehicles).},
	booktitle = {Wikipedia},
	urldate = {2024-01-14},
	date = {2024-01-06},
	langid = {english},
	note = {Page Version {ID}: 1193934250},
	file = {Snapshot:/Users/jonasprivat/Zotero/storage/6IY3YJ5L/Collective_animal_behavior.html:text/html},
}


@incollection{bays_introduction_2010,
	location = {London},
	title = {Introduction to Cellular Automata and Conway’s Game of Life},
	isbn = {978-1-84996-217-9},
	url = {https://doi.org/10.1007/978-1-84996-217-9_1},
	abstract = {Although cellular automata has origins dating from the 1950s, widespread popular interest did not develop until John Conway’s “Game of Life” cellular automaton was initially revealed to the public in a 1970 Scientific American article (Gardner in Sci. Am. 223:120–123, 1970). The feature of his “game” that probably evoked this intensive interest was the discovery of “oscillators” (periodic forms) and “gliders” (translating oscillators). This introductory chapter is for those who are either unfamiliar with the game, or feel that a brief “refresher course” would be appropriate.},
	pages = {1--7},
	booktitle = {Game of Life Cellular Automata},
	publisher = {Springer},
	author = {Bays, Carter},
	editor = {Adamatzky, Andrew},
	urldate = {2024-01-14},
	date = {2010},
	langid = {english},
	doi = {10.1007/978-1-84996-217-9_1},
	keywords = {Cellular Automaton, Heavyweight Spaceship, Moore Neighborhood, Periodic Form},
}

@incollection{rendell_turing_2002,
	location = {London},
	title = {Turing Universality of the Game of Life},
	isbn = {978-1-4471-0129-1},
	url = {https://doi.org/10.1007/978-1-4471-0129-1_18},
	abstract = {This chapter describes a Turing machine built from patterns in the Conway’s Game of Life cellular automaton. It outlines the architecture of the construction, the structure of its parts and explains how the machine works. It also illustrates the principle choices made during the design0 [17]. Background information about Turing machines, minimal universal Turing machines (those that simulate any other Turing machine) and non-erasing Turing machines can be found in [20,7,15,14,18]. The importance of Turing machines is the existence of universal Turing machines. Thus a machine that can simulate any Turing machine can simulate a universal Turing machine. It has been proved that Turing machines can be simulated by many types of machine: cellular automata (as one can see in this and other chapters of this book), random access machines [4], register machines [1] and others. In particular Minsky [16] describes a register machine which can simulate a Turing machine. The registers have the unusual property of being able to store positive numbers of any size. Remarkably, a long time ago Conway described [1] a method of constructing a register of this form in the Game of Life. This is discussed later in this chapter.},
	pages = {513--539},
	booktitle = {Collision-Based Computing},
	publisher = {Springer},
	author = {Rendell, Paul},
	editor = {Adamatzky, Andrew},
	urldate = {2024-01-14},
	date = {2002},
	langid = {english},
	doi = {10.1007/978-1-4471-0129-1_18},
	keywords = {Finite State Machine, Heavy Weight Space Ship, Memory Cell, Register Machine, Turing Machine},
}


@online{noauthor_elementary_nodate,
	title = {Elementary knightship - {ConwayLife}.com},
	url = {https://conwaylife.com/forums/viewtopic.php?f=2&t=3303},
	urldate = {2024-01-14},
	file = {Elementary knightship - ConwayLife.com:/Users/jonasprivat/Zotero/storage/CNJ2LWMP/viewtopic.html:text/html},
}


@book{tauber_critical_2014,
	location = {Cambridge},
	title = {Critical Dynamics: A Field Theory Approach to Equilibrium and Non-Equilibrium Scaling Behavior},
	isbn = {978-0-521-84223-5},
	shorttitle = {Critical Dynamics},
	abstract = {Introducing a unified framework for describing and understanding complex interacting systems common in physics, chemistry, biology, ecology, and the social sciences, this comprehensive overview of dynamic critical phenomena covers the description of systems at thermal equilibrium, quantum systems, and non-equilibrium systems. Powerful mathematical techniques for dealing with complex dynamic systems are carefully introduced, including field-theoretic tools and the perturbative dynamical renormalization group approach, rapidly building up a mathematical toolbox of relevant skills. Heuristic and qualitative arguments outlining the essential theory behind each type of system are introduced at the start of each chapter, alongside real-world numerical and experimental data, firmly linking new mathematical techniques to their practical applications. Each chapter is supported by carefully tailored problems for solution, and comprehensive suggestions for further reading, making this an excellent introduction to critical dynamics for graduate students and researchers across many disciplines within physical and life sciences.},
	pagetotal = {488},
	publisher = {Cambridge University Press},
	author = {Täuber, Uwe C.},
	date = {2014-03-06},
}


@online{blazek_blackbox_2022,
	title = {Why we will never open deep learning’s black box},
	url = {https://towardsdatascience.com/why-we-will-never-open-deep-learnings-black-box-4c27cd335118},
	abstract = {But we can still blow the whole thing up},
	titleaddon = {Medium},
	author = {Blazek, Paul J.},
	urldate = {2024-01-21},
	date = {2022-03-02},
	langid = {english},
	file = {Snapshot:/Users/jonasprivat/Zotero/storage/4LY9MVT4/why-we-will-never-open-deep-learnings-black-box-4c27cd335118.html:text/html},
}

@inproceedings{lundberg_unified_2017,
	title = {A Unified Approach to Interpreting Model Predictions},
	volume = {30},
	url = {https://papers.nips.cc/paper_files/paper/2017/hash/8a20a8621978632d76c43dfd28b67767-Abstract.html},
	abstract = {Understanding why a model makes a certain prediction can be as crucial as the prediction's accuracy in many applications. However, the highest accuracy for large modern datasets is often achieved by complex models that even experts struggle to interpret, such as ensemble or deep learning models, creating a tension between accuracy and interpretability. In response, various methods have recently been proposed to help users interpret the predictions of complex models, but it is often unclear how these methods are related and when one method is preferable over another. To address this problem, we present a unified framework for interpreting predictions, {SHAP} ({SHapley} Additive {exPlanations}). {SHAP} assigns each feature an importance value for a particular prediction. Its novel components include: (1) the identification of a new class of additive feature importance measures, and (2) theoretical results showing there is a unique solution in this class with a set of desirable properties. The new class unifies six existing methods, notable because several recent methods in the class lack the proposed desirable properties. Based on insights from this unification, we present new methods that show improved computational performance and/or better consistency with human intuition than previous approaches.},
	booktitle = {Advances in Neural Information Processing Systems},
	publisher = {Curran Associates, Inc.},
	author = {Lundberg, Scott M and Lee, Su-In},
	urldate = {2024-01-21},
	date = {2017},
	file = {Full Text PDF:/Users/jonasprivat/Zotero/storage/L8QR2KUL/Lundberg and Lee - 2017 - A Unified Approach to Interpreting Model Predictio.pdf:application/pdf},
}

@software{github_shapshap_2024,
	title = {shap/shap},
	rights = {{MIT}},
	url = {https://github.com/shap/shap},
	abstract = {A game theoretic approach to explain the output of any machine learning model.},
	publisher = {shap},
	urldate = {2024-01-21},
	date = {2024-01-21},
	note = {original-date: 2016-11-22T19:17:08Z},
	keywords = {deep-learning, explainability, gradient-boosting, interpretability, machine-learning, shap, shapley},
}


@article{explainable_ai_systematic_2023,
	title = {A systematic review of Explainable Artificial Intelligence models and applications: Recent developments and future trends},
	volume = {7},
	issn = {2772-6622},
	url = {https://www.sciencedirect.com/science/article/pii/S277266222300070X},
	doi = {10.1016/j.dajour.2023.100230},
	shorttitle = {A systematic review of Explainable Artificial Intelligence models and applications},
	abstract = {Artificial Intelligence ({AI}) uses systems and machines to simulate human intelligence and solve common real-world problems. Machine learning and deep learning are Artificial intelligence technologies that use algorithms to predict outcomes more accurately without relying on human intervention. However, the opaque black box model and cumulative model complexity can be used to achieve. Explainable Artificial Intelligence ({XAI}) is a term that refers to Artificial Intelligence ({AI}) that can provide explanations for their decision or predictions to human users. {XAI} aims to increase the transparency, trustworthiness and accountability of {AI} system, especially when they are used for high-stakes application such as healthcare, finance or security. This paper offers systematic literature review of {XAI} approaches with different application and observes 91 recently published articles describing {XAI} development and applications in healthcare, manufacturing, transportation, and finance. We investigated the Scopus, Web of Science, {IEEE} Xplore and {PubMed} databases, to find the pertinent publications published between January 2018 to October 2022. It contains the published research on {XAI} modelling that were retrieved from scholarly databases using pertinent keyword searches. We think that our systematic review extends to the literature on {XAI} by working as a roadmap for further research in the field.},
	pages = {100230},
	journaltitle = {Decision Analytics Journal},
	shortjournal = {Decision Analytics Journal},
	author = {A., Saranya and R., Subhashini},
	urldate = {2024-01-21},
	date = {2023-06-01},
	keywords = {Artificial Intelligence, Deep learning, Explainable Artificial Intelligence, Explanation, {HealthCare}, Machine learning},
	file = {ScienceDirect Snapshot:/Users/jonasprivat/Zotero/storage/SRRGZ3BI/S277266222300070X.html:text/html},
}

@article{bruzewicz_trapped-ion_2019,
	title = {Trapped-ion quantum computing: Progress and challenges},
	volume = {6},
	issn = {1931-9401},
	url = {https://doi.org/10.1063/1.5088164},
	doi = {10.1063/1.5088164},
	shorttitle = {Trapped-ion quantum computing},
	abstract = {Trapped ions are among the most promising systems for practical quantum computing ({QC}). The basic requirements for universal {QC} have all been demonstrated with ions, and quantum algorithms using few-ion-qubit systems have been implemented. We review the state of the field, covering the basics of how trapped ions are used for {QC} and their strengths and limitations as qubits. In addition, we discuss what is being done, and what may be required, to increase the scale of trapped ion quantum computers while mitigating decoherence and control errors. Finally, we explore the outlook for trapped-ion {QC}. In particular, we discuss near-term applications, considerations impacting the design of future systems of trapped ions, and experiments and demonstrations that may further inform these considerations.},
	pages = {021314},
	number = {2},
	journaltitle = {Applied Physics Reviews},
	shortjournal = {Applied Physics Reviews},
	author = {Bruzewicz, Colin D. and Chiaverini, John and {McConnell}, Robert and Sage, Jeremy M.},
	urldate = {2024-01-24},
	date = {2019-05-29},
	file = {Snapshot:/Users/jonasprivat/Zotero/storage/RV925NWR/Trapped-ion-quantum-computing-Progress-and.html:text/html;Submitted Version:/Users/jonasprivat/Zotero/storage/6JE7L6F8/Bruzewicz et al. - 2019 - Trapped-ion quantum computing Progress and challe.pdf:application/pdf},
}


@online{maertens_smarticle_lane_vid,
	title = {{TASEP}/{TASEP}-Smarticles/vids/speed\_gradient.mp4 at main · jonasmaertens/{TASEP}},
	url = {https://github.com/jonasmaertens/TASEP/raw/main/TASEP-Smarticles/vids/speed_gradient.mp4},
	urldate = {2024-01-24},
	file = {TASEP/TASEP-Smarticles/vids/speed_gradient.mp4 at main · jonasmaertens/TASEP:/Users/jonasprivat/Zotero/storage/9MT6PVL8/speed_gradient.html:text/html},
}

@online{maertens_smarticle_lane_vid_local,
	title = {{TASEP}/{TASEP}-Smarticles/vids/equilibration\_lanes\_local\_compr.mp4 at main · jonasmaertens/{TASEP}},
	url = {https://github.com/jonasmaertens/TASEP/raw/main/TASEP-Smarticles/vids/equilibration_lanes_local_compr.mp4},
	urldate = {2024-01-24},
}







