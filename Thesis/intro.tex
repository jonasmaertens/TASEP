\graphicspath{{img/intro/}}


\chapter{Introduction}
\label{ch:intro}

\section{Artificial Intelligence}
\label{sec:artificial-intelligence}
Artificial Intelligence (AI) is a broad subject of study that can be defined in different ways~\cite[chapter 1]{russell_artificial_2021}.
John McCarthy, often called the “father of AI”\cite{wiki_ai_2023, woo_fatherofai_2014, andresen_fatherofai_2002}, defines it as “the science and engineering of making intelligent machines”~\cite{stanford-whatisai}, where intelligence means “the computational part of the ability to achieve goals in the world”~\cite{stanford-whatisai}.
AI is sometimes mistakenly used interchangeably with Machine Learning.
Machine learning is a subset of AI concerned with enabling AI systems to learn from experience~\cite[chapter 1]{russell_artificial_2021}.
Machine learning enables the development of large-scale AI systems as they are used today.
\\
The study of artificial intelligence was first proposed by McCarthy et al. in late 1955 \cite{mccarthy_proposal_1955}.
It went through two major hype cycles in the sixties and the eighties~\cite{googlengram_ai, wiki_ai_2023, sitnflash_history_2017} followed by phases of “AI winter”.
The current (as of early 2024) AI boom, sometimes also called “AI spring”~\cite{aispring} was started by groundbreaking advances in speech recognition~\cite{hinton_deep_2012} and image classification~\cite{krizhevsky_imagenet_2012} in 2012~\cite{google_decade_2021, house_2012_2019} and reached the general public at the latest in late 2022, following the release of ChatGPT~\cite{openai_chatgpt_intro}, a multipurpose AI-chatbot, open to everyone~\cite{openai_chatgpt}.
\\
These breakthroughs are made possible mainly by advancements in the field of machine learning, enabling AI systems to learn from huge amounts of data.
In addition, the exponential increase in computation and storage capabilities as predicted by Moore’s Law~\cite{mooreslaw}, algorithms like backpropagation~\cite{rumelhart_learning_1986} allowed incorporating large amounts of data into machine learning models in realistic amounts of time.
\\
Today, AI systems are indispensable in many areas such as web search engines~\cite{google_howweuseai}, recommendation systems~\cite{burke_recommender_2011}, human speech recognition and generation~\cite{elevenlabs, hinton_deep_2012}, image recognition and generation~\cite{midjourney, krizhevsky_imagenet_2012} and personal assistants~\cite{openai_chatgpt_intro} and surpasses humans in high level strategy games like go and chess~\cite{silver_mastering_2016, silver_mastering_2017} as well as other videogames~\cite{piper_ai_2019}.

\section{Neural Networks}
\label{sec:neural-networks}
\subsection{Overview}
\label{subsec:overview}
At the heart of almost all the technologies mentioned in the last paragraph are deep artificial neural networks.
The next section will outline the mathematical details of how these systems work and learn.
Although the comparison of artificial neural networks, from now on just called “neural networks”, to their biological counterpart can be criticized as oversimplifying the inner workings of biological brains~\cite[chapter 1.1]{aggarwal_neural_2018}, the architecture of neural networks is heavily inspired by how decision-making and learning work in the human brain~\cite[chapter 1.1]{aggarwal_neural_2018, mit_nnexplained}.
I will illustrate the basic principles of neural networks at the example of a network that detects the gender of a person by looking at pictures.
\\
\\
A neural network consists of a number of layers of artificial neurons, called \textit{nodes}.
In a \textit{fully connected} network, each node is connected to every node in the next layer.
The connection strengths are called \textit{weights}.
An image of a person can be fed into the network by setting the \textit{activation} values of the first layer of the network, the \textit{input layer}, to the individual pixel values of the image.
This information is then fed forward through the layers of the network until the \textit{output layer} is reached.
If a network has at least one layer in between the input and output layer, it is called a \textit{deep neural network}.
These intermediate layers are called \textit{hidden layers}.
If the outputs of each layer are only connected to the inputs of the next layer, the network is called a \textit{feedforward neural network}.
If \textit{feedback} connections are allowed, the network is called a \textit{recurrent neural network}.
\\
In our example, the output layer should consist of only two nodes.
If the activation of the first node is larger than the activation of the second node, the network thinks that the person in the picture is a male.
If on the other hand the second node has a larger activation, the network classifies this person as female~\cite[chapter 1.2]{aggarwal_neural_2018}.
\\
\\
In order to make accurate predictions, a reasonable set of network parameters (i.e.the weights) has to be found.
This is done by training the network with pre-classified images.
After an image has been processed by the network, the output is compared to the correct classification and the network parameters are updated in a way that would improve the networks output if the same image was to be processed again~\cite[chapter 1.2]{aggarwal_neural_2018,ibm_nn}.
\\
This is similar to how humans learn from experience.
If we were to misclassify a persons gender, the unpleasant social experience that may come with that mistake would cause us to update our internal model of what different genders look like so as to not make the same mistake again.
\\
\\
One of the main strengths of neural networks is their ability to \textit{generalize}~\cite{gonfalonieri_understand_2020}.
When a network was trained on a large enough set of examples, it gains the ability to generalize this knowledge to examples that were previously unseen.
The gender classification network from our example doesn't just memorize the genders of the people it has seen, but instead learns about the features that help to identify the gender of a random person.
\\
\\
The problem of image classification is a rather complex one.
One wouldn't typically think of it as finding a function that maps the values of each input pixel to the classification output.
But even very complex problems can be modeled by equally complex functions.
The universal approximation theorem states, that a feedforward neural network with at least one hidden layer with appropriate activation functions (see~\ref{subsec:nn-mathematical-details} for details) can approximate any continuous function if given enough nodes~\cite[chapter 6.4.1]{goodfellow_deep_2016}.
That's why training a neural network can be thought of as fitting the network to the training data.
\\
\subsection{Mathematical Details}
\label{subsec:nn-mathematical-details}
%%Aggarwal Ch. 1.2, 1.3
%%Goodfellow Ch. 5, 6
%%IBM Gradient Descent
%%Haykin Ch. 4.4
